### Post Lecture 整理
4 parts
1) Generate random numbers
	1) LFSR: to generate random bits
2) RSA (asymmetric encryption algorithm)
3) AES (symmetric encryption algorithm)
	1) Padding oracle: [good visual explanation](https://www.nccgroup.com/us/research-blog/cryptopals-exploiting-cbc-padding-oracles/)

Part 1: generate random numbers
- What do we care about?
	- Working out what the initial seed is
- Why do we care?
	- 
- Basic principle
	- Computers cannot generate truly random numbers
	- Random-num generating algorithms rely on a "seed", an initial value
	- If you feed an algo with the same seed, it will generate the same sequence of random nums. Always!
		- Bad seed choices:
			- current time (second) > why? Because if you run the random function within the same second, it will return the same random number. This random number may be used as a seed. If attacker guesses correctly the time at which some target program runs, and the program uses that random value to do something crypto, the attacker can replicate the whole program by getting hold of the random value.
- Generate random bits
	- Also random bytes > just generate 8 random bits every time you want a random byte
	- Algorithm: LFSR
		- Begin with initial seed value and 2 chosen bit positions
		- Right-shift seed value. The popped-off bit is the first random generated bit
		- Fill in the missing bit at the most-sig position by XOR-ing the bits at the 2 chosen positions (prior to right-shift)
		- Rinse and repeat!
	- Problem
		- The popped-off bits, taken in reverse, form the original seed > based on the sequence of randomly-generated bits, the attacker can work out the seed
	- Encryption using LFSR-generated bytes
		- Steps: 
			- you have a msg you wanna encrypt 
			- generate a random byte > put into array called keystream; it will be a key
			- generate as many random bytes as len(msg)
			- now, encrypt each char of the msg: encrypted`[i]` = msg`[i]` XOR keystream`[i]`
				- Each char has its own encryption key
		- Goal of attacker
			- The attacker can 
			- Reverse-engineer EVERY SINGLE KEY within keystream
				- Assumptions: 
					- Can access encrypted char
					- Can guess correctly what this char decrypted is (judge by context: for example, flags always begin with "f")
				- key = encrypted char XOR decrypted char
				- What do we do with this key??? Isn't it completely useless for decrypting other chars because they use other keys?
					- Ans: Remember how these keys were generated? Using LFSR. The first key generated, taken in reverse, is the initial seed value. If we have this seed, we can re-run LFSR and get ALL our keys in order. And then, we can apply each key to the corresponding encrypted char to obtain the decrypted char.
			- Summary
				- Get the key for the first char > get seed
					- The key was generated using LFSR and it's special in that it is the initial seed, in reverse, by virtue of LFSR's algorithm
				- Run LFSR using this seed to generate every key byte
				- Apply each key byte to corresponding encrypted char to obtain decrypted char
				- Get the entire decrypted string!




Cryptography is arguably the most important part of the modern internet. Without it, all internet traffic—including requests, responses, and passwords—would be transmitted in plaintext and observable to other parties on the network and all infrastructure between the client and destination. With cryptography, programs can institute proper privacy and anonymity protections. Some software, including apps like Signal for secure communication, use their cryptographic security as a sales pitch to promote use. Meanwhile, others may view cryptography as a means to an end.

In either case, it is imperative that cryptographic security of software systems be strongly vetted to ensure that user information, including private user data, usernames, and passwords are all strongly protected. Assessing the security of new algorithms is a significant undertaking, one that requires a deep understanding of cryptographic properties and perhaps a strong background in mathematics. But there is also a place for vulnerability researchers in cryptographic assessments.

In this lesson we focus specifically on incorrect implementations of cryptography and randomization, a skill which requires an understanding of cryptography but not necessarily a deep experience with a particular algorithm. We start by focusing on randomization, which is a key component of pseudo-random number generators that computers use in cryptography. Then, we focus on incorrect implementations of common cryptographic algorithms: RSA and AES.

Table of Contents
* [[#Randomization]]
	* [[#C's `srand`]]
	* [[#LFSR]]
	* [[#LFSR Internals]]
* [[#Encryption]]
	* [[#RSA]]
	* [[#RSA Attacks]]
	* [[#AES]]
	* [[#Padding Oracle Attacks]]
* [[#Recitation]]
* [[#Next Steps]]

## Randomization

Generating random numbers is incredibly important for generating random keys and seeds. Random numbers guarantee the next number generated will not be predictable. However, generating truly "random" data is hard—after all, we are dealing with deterministic machines that require instructions to operate.
- Does using same seed give us the same sequence of "random" nums? 
	- Yes

Computer science relies on [Pseudo-Random Number Generators (PRNGs)](https://en.wikipedia.org/wiki/Pseudorandom_number_generator) which are algorithms that generate a seemingly random number given an initial seed value. If the PRNG is truly "random," then an attacker without knowledge of the seed will have no better than a 50% chance of guessing that the next bit generated is a 0 or a 1. PRNGs are also used in encryption functions to ensure the output adheres to the same standards. The choice of a good source of randomization can be the difference between a completely secure application or trivially cracking the cryptography.

### C's `srand`

A historically common way of generating random numbers in C and C++ are the native `srand` and `rand` functions. `srand` "seeds" the random number generator based on a seed value. Once seeded, every subsequent integer returned by `rand()` is a randomized integer. This seems logical, except we have one problem: the seed needs to be a random value so that the algorithm is truly random. So we have a chicken or the egg dilemma—we need a random value to seed the algorithm but we cannot get a random value until the algorithm is seeded!

**What to use as seed?**
- Choice 1: current time (second)
	- Why dangerous?
		- If attacker figures out the time at which the program ran, they can reproduce those "random" nums
			- How to figure out this time??
		- the fact that it's in seconds
			- if you run rand() multiple times within the same second, you get the same number
The historically popular solution is use a value that is always changing: the current time (in seconds) from the [UNIX epoch](https://en.wikipedia.org/wiki/Unix_time)! This is easily retrieved in C with the `time(NULL);` call. This is a good idea with two very bad caveats.

First, the seed only changes once every _second_. That seems like a pretty quick interval, but computers execute in fractions of a second. This means that every call to `srand` during the same second produces an identical output. Consider the following program, [[bad_srand.c]]:

```c
#include "stdio.h"
#include "stdlib.h"
#include "time.h"

int main() {
    for (int i = 0; i < 0x10; i++) {
        srand(time(NULL));  // time(NULL) is the seed
        int r = rand();
        printf("Random number: 0x%x\n", r);
    }
    return 0;
}
```

This program seeds the randomization algorithm 16 times using the current time, and generates one random integer for every seed. The result from running the compiled [[bad_srand]] program clearly demonstrates that one second is too long of an interval, as all produced values are the same!

```
Random number: 0x227af3a3
Random number: 0x227af3a3
Random number: 0x227af3a3
Random number: 0x227af3a3
Random number: 0x227af3a3
Random number: 0x227af3a3
Random number: 0x227af3a3
Random number: 0x227af3a3
Random number: 0x227af3a3
Random number: 0x227af3a3
Random number: 0x227af3a3
Random number: 0x227af3a3
Random number: 0x227af3a3
Random number: 0x227af3a3
Random number: 0x227af3a3
Random number: 0x227af3a3
```

One could argue this issue is not really that bad—how often are we seeding multiple random number generators at the same time within an application? Rather, we would generally see the generator once and then continue generating random values once seeded. That is a fair argument, but the second issue is much worse.

The chose of `time(NULL)` as a seed assumes that nobody else can determine the time at which the seed occurred. This is not necessarily true, as an attacker might have information on how long a particular service has been running (to calculate the UNIX epoch time) or may control _when_ the randomization occurs. Consider a target program [[bad_randomization.c]], which can be spawned at any point by a user (we could visualize this as part of a binary that is spawned when a user connects to a server port):

```c
#include "stdio.h"
#include "stdlib.h"
#include "time.h"

int main() {
    srand(time(NULL));
    int r = rand();
    printf("Random number from C: 0x%x\n", r);
    return 0;
}
```

Running the [[bin/lesson13/bad_randomization|program]] a few times in a row shows totally different outputs. Secure, right? 

```
$ ./bad_randomization 
Random number from C: 0x53f98907
$ ./bad_randomization 
Random number from C: 0x900d6c
$ ./bad_randomization 
Random number from C: 0x787c92cd
$ ./bad_randomization 
Random number from C: 0x667ffb45
```

Unfortunately not. If we can influence when the binary is spawned, and thus when the randomization occurs, we can generate a Python script to create _the same random number_. This requires the Python `ctypes` utility to wrap C binaries and execute them directly. Specifically, we want to pull out the functionality for `srand`, `rand`, and `time` functions to mimic what the C program does. The [[python_srand.py]] script performs the following:

```python
import ctypes
import time

libc = ctypes.CDLL("libc.so.6")

# Define the time function
libc.time.argtypes = [ctypes.POINTER(ctypes.c_long)]  # time returns a long
libc.srand.argtypes = [ctypes.c_uint]  # srand takes an unsigned int

# Call time(NULL) to get the current time
current_time = ctypes.c_long()
libc.time(ctypes.byref(current_time))

# Seed the random number generator with the current time
libc.srand(ctypes.c_uint(current_time.value))

libc.rand.restype = ctypes.c_int  # rand returns an int
random_number = libc.rand()

print("Random number from Python: " + hex(random_number))
```

If we run the programs at the same time, the results are the same!

```console
$ python3 python_srand.py && ./bad_randomization // run both at the SAME time
	Random number from Python: 0x7ce19cfe // we get the same random num!
Random number from C: 0x7ce19cfe
```

- Takeaway: run it at the same second (time), it returns the same "random" number


This demonstrates a powerful primitive: if we can control or estimate the time at which a server spawns a binary and makes a call to `srand`, we can initialize the same PRNG and mimic all randomized calls that the target makes! We can use this to our advantage when attacking systems that use `srand(time(NULL))`. 


Ok, so srand() is bad if we use current time as seed, because ran within the same second will return the same random number. Attackers can exploit if they can infer what time the program was ran...

#### `srand` Alternatives
- use 4 bytes from a file on your system `/dev/urandom`
	- this file generates bytes based on activities like mouse clicks, keyboard inputs
	- they call it "sourcing entropy"
	- Not truly random in the sense that if you figure out sequence of mouse clicks, inputs etc. and the algorithm by which /dev/urandom uses to generate bytes, you can in theory get those random nums back. But in practice? Practically impossible.

One would think after the prior demonstration that `srand(time(NULL))` would be a discouraged means of generating random numbers. Unfortunately, its vulnerability is often glossed over. In fact, DigitalOcean's [guide for generating random numbers in C++](https://www.digitalocean.com/community/tutorials/random-number-generator-c-plus-plus) currently _recommends_ that strategy. Consequently, it is used frequently in even modern systems.

There are better alternatives for fetching randomized data in C and C++. Instead of using `time(NULL)` to generate a random integer, we can instead read four bytes from `/dev/urandom` (on UNIX systems) to get bytes that are randomized based on the [entropy of the system](https://en.wikipedia.org/wiki//dev/random). The [[good_randomization.c]] example shows how to use bytes from `/dev/urandom` to generate random values. Running the [[good_randomization]] binary shows that it securely generates a different number every time when reseeded in a loop:

```
Random number: 0x45a2f46b
Random number: 0x4e499b49
Random number: 0x6b8c0e69
Random number: 0x23da21be
Random number: 0x314a03ac
Random number: 0x7dcabb0c
Random number: 0x13f67882
Random number: 0x4de7fe33
Random number: 0x348e3e6
Random number: 0x3b1f3393
Random number: 0x698007e3
Random number: 0x5bf8c9af
Random number: 0x1978301e
Random number: 0x8752242
Random number: 0x28f0c297
Random number: 0x339e5af
```

### LFSR
- An algorithm to generate random bits/bytes
	- Requires: an intial seed

Another means of generating random bits and bytes is the Linear Feedback Shift Registers (LFSR) algorithm. This is similar to `srand()` in that it requires an initial seed (state), from which pseudo-random numbers can be generated. Let's first take a look at how the algorithm works, and then focus on how to break it.

#### LFSR Internals

LFSR maintains a `k`-bit register that must be initialized with a seed value. LFSRs set _taps_ on certain bit indices within the register that define the calculation of the next state. It is easiest to understand this by visualizing an example.

Consider an 8-bit LFSR register with taps on bits 2 and 6. If initialized with the value `0x57`, the initial state is `01010111`. The first random bit generated is the rightmost bit, and all other bits are shifted right by 1. This means the first random bit generated is a 1.
- seed = 0x57 (binary: 01010111)
	- How is this generated? Depends. Maybe current time.
- 1st random bit is the least-sig bit (get by right-shifting the number)
	- DANGER!!!!!
		- Because you keep producing "random" bits by right-shifting the number and taking the bit, the first 8 bits you get out spells out the original number, starting with least-sig bit! 
			- Getting the original num = getting the seed
- What do we do with the missing most-sig bit position?
	- Fill it by XOR with tap positions (here: 2 and 6)

| Step | 0   | 1   | 2   | 3   | 4   | 5   | 6   | 7   |     | output |
| ---- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ------ |
| 0    | 0   | 1   | 0   | 1   | 0   | 1   | 1   | 1   |     |        |
| 1    |     | 0   | 1   | 0   | 1   | 0   | 1   | 1   |     | 1      |

The missing leftmost bit is determined by an XOR of all tap bits. This LFSR defines taps on bit indices 2 and 6, meaning the new bit is `0 ^ 1 = 1`. These bits are italicized below, and the new bit it stored in the leftmost index.

| Step | 0   | 1   | 2   | 3   | 4   | 5   | 6   | 7   |     | output |
| ---- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ------ |
| 0    | 0   | 1   | *0* | 1   | 0   | 1   | *1* | 1   |     |        |
| 1    | 1   | 0   | 1   | 0   | 1   | 0   | 1   | 1   |     | 1      |

This process continues for subsequent bits until the required number of pseudo-random bits are generated. If the program requests one byte, the process would iterate eight times as follows:

| Step | 0   | 1   | 2   | 3   | 4   | 5   | 6   | 7   |     | output |
| ---- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ------ |
| 0    | 0   | 1   | *0* | 1   | 0   | 1   | *1* | 1   |     |        |
| 1    | 1   | 0   | *1* | 0   | 1   | 0   | *1* | 1   |     | 1      |
| 2    | 0   | 1   | *0* | 1   | 0   | 1   | *0* | 1   |     | 1      |
| 3    | 0   | 0   | *1* | 0   | 1   | 0   | *1* | 0   |     | 1      |
| 4    | 0   | 0   | *0* | 1   | 0   | 1   | *0* | 1   |     | 0      |
| 5    | 0   | 0   | *0* | 0   | 1   | 0   | *1* | 0   |     | 1      |
| 6    | 1   | 0   | *0* | 0   | 0   | 1   | *0* | 1   |     | 0      |
| 7    | 0   | 1   | *0* | 0   | 0   | 0   | *1* | 0   |     | 1      |
| 8    | 1   | 0   | *1* | 0   | 0   | 0   | *0* | 1   |     | 0      |

The output bits would be `11101010`, or `0xea`. Nice! Except there is one significant problem with this output...it is a reverse of the initial state!


### Attacking LFSR

As we demonstrated in the example above, the initial eight-byte state `01010111` produced the mirror image `11101010`. In fact, we can generalize this phenomenon more broadly. For any state in a `k`-bit LFSR register, the next `k` bits generated will be a mirror image of the internal state at the start of generation! This means that the security of the LFSR algorithm relies on the fact that an attacker can never learn the internal state.

Generally, output of an LFSR will be used to encrypt some data. For every message bit `m` encrypted with LFSR bit `r`, we can only see ciphertext bit `c` where `c = m ^ r`. With two unknowns, we cannot break the encryption to determine the initial register state nor the message.

But what if we know some plaintext which was encrypted along with its location in the ciphertext. This means we see the output `c` and know the input `m`, so we can calculate the LFSR bit `r` used in the encryption, `r = c ^ m`. This identifies a single bit of the internal state. But if we know `n` sequential message bits and their position in the output ciphertext, we can calculate `n` sequential internal state bits. If `n` is greater than the length `k` of the LFSR register, we have successfully identified the internal state!

Consider the prior example, which generated the pseudo-random output byte `0xea`. As an attacker, we would not see that byte, instead it would be used by the target to encrypt a message character. Say the output of that encryption is `0xa2`, which we are able to see as an attacker. Without any other prior knowledge, this would be an arbitrary byte produced by the XOR of a randomly generated byte and an unknown message character. But let's say from context clues that we know the character that was encrypted was the character `H` (ASCII value `0x48)`. With that knowledge, we can calculate the randomly generated byte `r = 0xa2 ^ 0x48 = 0xea`. If we know that the LFSR register which generated that random byte is eight bits long, we know the internal state used to create that byte was the reverse of `0xea`, or `01010111`!
- Given:
	- encrypted value = 0xa2
	- original char = H (ASCII 0x48)
	- encrypted value = some random byte (seed) XOR original char
- Calculate random seed:
	- seed = encrypted value XOR original char = 0xa2 ^ 0x48 = 0xea
- What do we do with the seed?
	- Given: In LFSR, the seed is the intial value we use to generate random bits by right-shifting and filling in most-sig bit by XOR bits at tap positions (two total)
		- If we also know sth about the tap positions, we can replicate the sequence of random bits
- Tryna understand ...
	- To encrypt a char, we XOR the char with a secret value 
	- As an attacker, we only see the encryped values
	- Where do we get the secret value??
		- What does this have to with LFSR?
			- Ans: the secret value (8 bits here) is produced using LFSR, by LFSR with an initial seed which we don't know (yet)
			- secret value != seed
			- After working out the secret value, we reverse LFSR to get the intial seed (which was just the intial seed in reverse lmao)
			- With the initial seed, I can... reenact the whole encryption process?

 With this internal state we can do two things, presuming we know the location of the taps. First, we can replicate the LFSR ourselves and start generating the same pseudo-random bits as the target! This is similar to the `srand` attack in the previous section, since we have essentially identified the "seed" that is used to generate the next random bits. A second alternative is that the LFSR can be replayed _backwards_. Since the algorithm is simply shifts and XORs, we can use the taps and the output bits to calculate previous states. This allows us to decrypt all prior traffic, breaking encryption for all previous and future transmissions.

### LFSR Practical Example

Consider the LFSR defined in the following Python class, included in [[lfsr.py]]:

```python
import binascii
from functools import reduce
from operator import xor
from pwn import remote

class LFSR:
    # 8-bit Fibonacci LFSR, characteristic polynomial:
    # Tap positions (0-indexed): 2, 6
    # Tap bits: 01010111
    def __init__(self, seed, bits=8, taps=(2, 6)):
        # Convert the seed to bits
        self.state = self.int_to_bits(seed)
        self.taps = taps
        self.tap_bits = [1 if i in taps else 0 for i in range(bits)]

    @classmethod
    def bits_to_int(cls, bits):
        b = 0
        for bit in bits:
            b = b << 1 | bit
        return b

    @classmethod
    def int_to_bits(cls, n, bits=8):
        return list(map(int,bin(n)[2:].zfill(bits)))

    def get_bit(self):
        out_bit = self.state[-1]
        # Compute the new state bit: XOR the tap bits
        # new_bit = reduce(xor,[x & y for x,y in zip(self.state, self.taps)])
        new_bit = reduce(xor,[self.state[i] for i in self.taps])
        # Shift the state
        self.state = [new_bit] + self.state[:-1]
        return out_bit

    def get_bits(self, n):
        return [self.get_bit() for _ in range(n)]

    def get_int(self, n):
        bits = self.get_bits(n)
        return self.bits_to_int(bits)

    def get_byte(self):
        return self.get_int(8)

    def get_bytes(self, n):
        return [self.get_byte() for _ in range(n)]

    def __str__(self):
        state_str = ''.join(map(str,self.state))
        taps_str = str(self.taps)
        return f"LFSR:\n  Taps:  {taps_str}\n  State: {state_str}"
```

This defines an eight-bit LFSR with taps on bits 2 and 6, as demonstrated above. As an attacker, we see a target generate an encrypted string `c5cbe0e47d499970b50ef3f4` (hexlified) using this LFSR. But, unfortunately, we do not know the initial seed state. Without any insight into the internal LFSR state, this is a secure transmission.

But say we have a feeling the message starts with the character `H`. We can calculate the first byte of the randomized LFSR output, `r`, as `r = 0x48 ^ 0xc5 = 0x8d` (0x48 is ASCII for H; 0xc5 is the first char of the string). This equates to `10001101` in binary. We know that these eight bits must have been produced by an LFSR with internal state equal to `10110001`, and because we know the LFSR maintains an eight-bit register, we have successfully identified the LFSR internal state!

We can use this information to create our own register, as shown in [[lfsr_solver.py]]. We initialize it to our identified state and produce 12 random bytes, matching the length of the ciphertext. For each random byte, we compute `m[i] = c[i] ^ r`, which decrypts the ciphertext using the random byte. Printing the output of this decryption shows that the original message was `Hello world!`!

```python
cat lfsr_solver.py                 
from lfsr import LFSR
import binascii

l = LFSR(0b10110001)
c = binascii.unhexlify(b"c5cbe0e47d499970b50ef3f4")
for i in c:
    r = l.get_byte()
    print(chr(r ^ i), end = "")

print()

# prints Hello world!
```

## Encryption

Random numbers allow us to generate secret keys for encryption, which protects our traffic secret from prying eyes. We focus on two different forms of encryption in this lesson, asymmetric and symmetric cryptography. Asymmetric cryptography involves a public and private key, allowing parties to use the publicly available key to encrypt a message to a desired recipient. Symmetric cryptography leverages a shared secret key so that parties can encrypt and decrypt messages using an algorithm with the same internal state. Both are imperative to modern cryptography, so we discuss common vulnerabilities and misconfigurations of each.focus on two different forms of encryption in this lesson, asymmetric and symmetric cryptography. Asymmetric cryptography involves a public and private key, allowing parties to use the publicly available key to encrypt a message to a desired recipient. Symmetric cryptography leverages a shared secret key so that parties can encrypt and decrypt messages using an algorithm with the same internal state. Both are imperative to modern cryptography, so we discuss common vulnerabilities and misconfigurations of each.

### RSA

One of the most foundational cryptographic algorithms is RSA. Along with Diffie-Hellman, RSA is fundamental in public key cryptography and allows the generation of public and private keys in the form of asymmetric cryptography. One of the most relevant and important applications of RSA is generation of SSL certificates. SSL forms the backbone of the [HTTPS](https://www.cloudflare.com/learning/ssl/what-is-https/) protocol which prevents MITM (man-in-the-middle) spoofing of web sites and encryption of web requests. First we discuss how RSA works and then review some common misconfigurations that result in insecure cryptography.

#### RSA Handshake

RSA is an asymmetric cryptographic algorithm, meaning it relies on a public and private key. A user generates this key pair and shares the public key with the wider world. Any party wishing to communicate with the user can use the public key to encrypt a message, and the user can use its private key to decrypt this secret. Without knowledge of the private key, all encrypted messages are protected.
- Asymmetric because what the person (secret-holder) has is not the same as the outside world
- Person has private and public keys
- Outside world only has public key
- Outside world can encrypt msgs using public key
- Person receives the encrypted msg, uses the private key to decrypt


The security of RSA relies upon primes, exponents, and moduli. 
**Steps to generate a private-public key pair:**
1. Pick two large primes: `p` and `q`
2. Compute `n = pq`. `n` is the public modulus which is shared between parties. Because `n` is calculated by the product of two prime numbers, it is a _semi-prime_ number
	1. Semi prime?? First time to hear of
3. Compute `phi = (p-1)(q-1)`. `phi` is the *totient* of `n`
4. Pick a number `e` co-prime to `phi` (usually 3, 5, 17, 257, 65537). Co-prime numbers are numbers that share no common divisors other than 1 (e.g., 8 and 9 are co-prime because they share no common factors)
	1. What is coprime?
		1. The only divisor that divides both numbers is 1
		2. The numbers that are coprime don't have to be prime themselves. 
5. Compute `d` such that `d * (e % phi) = 1`. `d` is the modular multiplicative inverse of `e % phi`. This is often written as `d * e = 1 (mod phi)`
	1. I don't get the second form of the equation...
6. `(n, e)` is the public key
7. `(n, d)` is the private key

**How to encrypt and decrypt with keys:**
Say Bob wants to talk with Alice. The two perform the following exchange:
1. Bob solicits Alice's public key, if not already known
2. Alice sends Bob the public key `(n, e)`
3. Bob encrypts a message `m` into ciphertext `c` by converting it to an integer (e.g., converting a character message string to bytes and converting those bytes to an integer) and plugging into the formula `c = m^e (mod n)`
4. Bob sends the ciphertext `c` to Alice
5. Alice decrypts the ciphertext `c` by raising it to the private exponent `d`: `m =c^d (mod n)`

Security relies on the fact that no other party other than Alice and Bob can decrypt the message. Alice has the private key and thus can decrypt with `m = c^d (mod n)`. For RSA to be secure, it must ensure that nobody intercepting the message can find `m` given `c`. To do so would require finding `p` and `q` given `n` (which is publicly transmitted). Being able to do so would allow an attacker to calculate `phi` and then the private key `d` (since `e` is also publicly transmitted). We do not formally prove this, but rather accept that it is a cryptographically hard problem to perform [integer factorization](https://en.wikipedia.org/wiki/Integer_factorization) on large semi-prime numbers (`n`). 

### RSA Attacks

Though RSA has proven to be a reliable algorithm, there are some common pitfalls that a user can make. It is important to know how to identify and exploit these misconfigurations. We'll cover two common vulnerabilities in the following section.

#### Small Exponent
- didn't get this

Part of the reason that RSA is secure is because the output `c` is the result of a very large number `m^e` taken modulus some `n`. The modular arithmetic serves as a "trap door"—once the modulus is taken, we have no idea what the input was. Consider a simple example, `x % 11`. If we choose `x` as 0, 11, 22, 33, 44, etc., the result is 0. This makes determining `x` extremely difficult—we would need some context to differentiate a meaningful input versus an incorrect one—as there are infinite inputs that result in the answer 0. 

This ensures security in the RSA calculation, _so long as `m^e` is larger than `n`_. If not, we end up in a scenario where `m^e (mod n) = m^e`. This generally occurs for small messages combined with insufficiently large exponents. Let's run through an example of how to crack `m` given `c` with a *small exponent attack*.

Let's say we want to communicate with Alice, who has transmitted a public key `(n = 1029964685039328183850565568301462712943401194108399899946655512155256138751939869839726896909497020242437716423669694613533538002265762544167039757025515830232881172912087540576473438902462095318458, e = 17)`. If we want to send the message "Hi!", we would perform the following steps:
1. Convert "Hi!" to an integer: `m = int.from_bytes("Hi!".encode(), "big") = 4745505`
2. Compute `c = m^e % n = 313907289126721340968087322354015840362444113671608072676602035367215907614018912936197777702214275131988525390625`
3. Transmit `313907289126721340968087322354015840362444113671608072676602035367215907614018912936197777702214275131988525390625` to Alice, where it can be decrypted with private key `d`

> Note, we use big-endian conversion above because otherwise the message would be reversed! We care about linear streams of bytes, so big-endian makes sense here.

The issue arises in that the resulting ciphertext `c = 313907289126721340968087322354015840362444113671608072676602035367215907614018912936197777702214275131988525390625`, is simply equal to `m^e`! Because the message was short and `e` was small, the computation `m^e < n`.

An attacker on the network would see the encrypted data `c` and could try to calculate the original message by finding `m = c^-e`. All this requires if finding the `e`th root of `c` to break the encryption!

#### Common Modulus Attack

Another vulnerable scenario is when a single user transmits the same encrypted message text (same `m`, different `c`) with the same modulus to two different users. Even if the private and public key pairs change per distribution (`e` and `d` are different for the transmissions), the identical modulus and message can lead to breaking encryption using only the two ciphertexts.
- what is "modulus"? m, aka original secret msg?
	- Oh, so as I understand: someone transmits the same msg twice
		- Every instance, different d and e values are used
			- Such that the encrypted forms differ in both instances
			- But n (=pq) remain the same
		- As an attacker, we can observe the two public keys: e_1, e_2. Based on their relationship, we can work out ... ???

m = original, unencrypted message
c_1 = encrypted m, the first time
c_2 = encrypted m, the second time
e is private key
d is public key

Goal: find a and b
- what are they? 
- why the fuck do we need them? to reconstruct the private key? Or the original msg directly?
- because by math magic, we have the equation that: `m = ((c_1 ** a) * (c_2 ** b)) % n`
	- Which means that once we have a, b (and c_1, c_2 which we see), we can calculate what the original msg `m` is
	- But the original n remains the same
		- n = pq so the two primes chosen are the same
		- phi = (p-1) (q-1) are the same bc primes are the same
		- e (public): any number that is coprime with phi 
			- e doesn't have to be a prime
		- d (private) such that d * (e mod phi) = 1

Let's see how this works concretely. Consider the same message `m` encrypted by public key pair `(n, e_1)` and `(n, e_2)`. This generates two different ciphertexts, `c_1` and `c_2` such that
* `c_1 = m^e_1 (mod n)`
* `c_2 = m^e_2 (mod n)`

- Conditions needed for this attack:
	- n (publicly visible) is the same for c_1 and c_2
	- `GCD(e_1, e_2) = 1`
		- e_1 and e_2 are... coprime?? Or they must both be primes? Ans: coprime.



If an attacker can observe these transmissions, they have access to `c_1, c_2, e_1, e_2, n`. In order to crack this problem, we need to establish a relationship between `e_1` and `e_2`. Public exponents are frequently prime values so that they conform to the RSA requirement of being co-prime with `phi`. If both are prime then we have the fact that the greatest common divisor (GCD) of `e_1` and `e_2` is 1. This may be true even if they are not prime, though it is certain if they are. We write this as `GCD(e_1, e_2) = 1`.
- Very often, e_1 and e_2 themselves ARE PRIME (not always.)
	- Remember, e is just chosen to be any number that is coprime with phi
	- Assuming e_1 and e_2 are primes:
		- Their only common divisor is 1 (`GCD(e_1, e_2) = 1`)
			- Why?
				- Primes by definition only have 1 as their divisor
				- When you have two primes, and both numbers only have 1 as their divisor, then their greatest common divisor (GCD) must be 1 //
		- From Bezout's Identity, given `GCD(x, y) = d`:
			- there exist integers a,b such that ax + by = d
		- Using Bezout's in our situation: 
			- GCD(e_1, e_2) = 1
			- There exist integers a,b such that a * e_1 + b * e_2 = 1
			- ^ This is the relationship between e_1 and e_2, the two exponents that form part of the public keys (different) used to encrypt the same msg
				- Next Step: find a, b 
					- WHY?
						- How we encrypted the same msg with the 2 different keys: 
							- c_1 = m^e_1 mod n (1)
							- c_2 = m^e_2 mod n  (2)
						- Once we solve a and b, plugging into a * e_1 + b * e_2 = 1 allows us to express e_1 in terms of e_2 (vice versa)
						- Goal: solve for m
						- Knowns: c_1, c_2, n
						- Unknowns: e_1 (not e_2 bc we express e_2 in terms of e_1), m
						- We have 2 equations (1), (2) and 2 unknowns. This is solvable!!!
						- Summary: The whole point of using Bezout's to find relationship between e_1 and e_2 is to reduce the number of unknowns down to 2, such that we can solve for m with the 2 equations we have.
					- HOW to solve for a,b ? 
						- solve for a: 
							- Equation: a * e_1 = 1 mod e_2
						- after you solved a...
						- solve for b: use Bezout's equation we got

Why does this matter? Because a particular identity, [Bezout's Identity](https://en.wikipedia.org/wiki/B%C3%A9zout%27s_identity), states that for integers `x` and `y` in which `GCD(x, y) = d`, there exist some other integers `a` and `b` such that `ax + by = d`. This can be applied to modular arithmetic using the [Extended Euclidian Algorithm](https://en.wikipedia.org/wiki/Extended_Euclidean_algorithm) such that there exist some `a` and `b` such that `a * e_1 + b * e_2 = 1`. We will not prove this mathematically but rather take it as a fact and apply it to this problem.

We can apply algebraically equivalent operations to the former encryption formulae such that:
- `original encryption formula ==> plug in e_1, e_2 in terms of a, b using Bezout's ==> rearrange to take m out to the front`
* `c_1 = m^e_1 (mod n) ==> c_1^a = (m^e_1)^a ==> c_1^a = m^(a * e_1)`
* `c_2 = m^e_2 (mod n) ==> c_2^b = (m^e_2)^b ==> c_2^b = m^(b * e_2)

The two equations are now:
- `c_1^a = m^(a * e_1)`
- `c_2^b = m^(b * e_2)`

Next, multiply the two equations together:
	`c_1^a * c_2^b` = `m^(a * e_1) * m^(b * e_2)`
Simplify RHS (m is the same base for both terms):
	`c_1^a * c_2^b` = `m^((a * e_1) + (b * e_2))`


We can get a little creative with these two results to try and cancel some operations out. Say we multiply `c_1^a * c_2^b`. Using the formulae above, that equates to `m^(a * e_1) * m^(b * e_2)` which resolves to `m^(a * e_1 + b * e_2)`. From the Extended Euclidian algorithm above, we know that taking this result over the modulus `n` means `a * e_1 + b * e_2 = 1`, and thus `c_1^a * c_2^b = m^1 = m` (all `mod n`)!

We now have an equation with two unknowns, `a` and `b`. But we know those are both integer values that satisfy the equation `a * e_1 + b * e_2 = 1` per Bezout's Identity. Let's rearrange this a bit. Let's consider taking this entire equation modulo `e_2`. The result is that the `b * e_2` term can be removed, since any combination of `x * y % y` will always result in a remainder of 0. Therefore, we have an equation with only one unknown: `a * e_1 = 1 (mod e_2)`, which just means that `a` is the multiplicative modular inverse of `e_1` mod `e_2`! We can find this quickly with Python's `gmpy2` module. Suppose `e_1 = 7` and `e_2 = 5`, the result for `a` is `3`!

```
pip3 install gmpy2
python3
>>> import gmpy2
>>> gmpy2.invert(7, 5)
>>> mpz(3)
>>> 3 * 7 % 5
1
```

Great! With `a` solved, we can focus on `b`. We can simply substitute `a` into Bezout's Identity and solve for `b`, such that `b = (1 - a * e_1) / e_2`. Continuing with the prior example:

```
>>> (1 - 3 * 7) // 5
-4
>>> 3 * 7 + -4 * 5
1
```

It makes sense that `b` is negative, as either `a` or `b` must be to solve `a * e_1 + b * e_2 = 1`. With our constants solved, we can get back to the matter at hand: cracking the ciphertexts using the equation `c_1^a * c_2^b = m (mod n)`! Python's `gmpy2` has a handy power utility called `gmpy2.powmod` for calculating the result of large exponential calculations such as this.

> Note: the result of this calculation is `m` as an _integer_. We need to convert this to raw bytes (and then perhaps printable ASCII, depending on our expected data). We can do this with the following Python code:
```python
# define m as the result of the calculation above
> import binascii
> print(binascii.unhexlify(hex(m)[2:]))
> # convert to hex string first (has 0x prefix), get rid of 0x prefix, unhexlify ???
```



### AES (Symmetric)

Asymmetric key pairs are pivotal in the initial exchange of information between two parties, since the public key pair is, well, public. But encryption can get expensive for lengthy communication. A quicker alternative is a _symmetric cryptographic algorithm_, where both parties share the same key and cipher algorithm. An asymmetric algorithm like RSA or Diffie-Hellmen can assist in the creation and sharing of this shared secret key, after which encryption can switch to a symmetric cipher.

One of the simplest symmetric algorithms is the Caesar cipher which uses a shared secret key to shift the letters of a message. This was an effective means of encryption 2000+ years ago, but modern systems make this algorithm trivial to break. Nowadays, we use stream and block ciphers for protecting sensitive messages.

Stream ciphers sequentially encrypt a message a bit or byte at a time whereas block ciphers operate on "chunks" of the message. The modern block encryption standard is the Advanced Encryption Standard (AES).

#### AES Internals

The AES algorithm is defined by its block size, either 128, 192, or 256 bits. This choice determines both the shared secret key size and the length of data that it operates on while encrypting. AES-128, for example, operates on 16-byte blocks of data and uses a 16-byte key. The key determines an unique internal state within the algorithm such that a block of bytes passed into the algorithm is transformed into seemingly random output. The algorithm is reversible such that any party with knowledge of the key can decrypt ciphertext the ciphertext block.
- what is a "block"?
	- a fixed-sized chunk of data

##### ECB Mode

AES has different modes of encryption which influence how the output ciphertext is calculated. The simplest mode is Electronic Code Book (ECB) mode. This mode initializes a unique internal state based on the secret key and encrypts a block of input into a corresponding block of ciphertext output. _The output is dependent only upon the secret key (which influences the internal state) and the input bytes._ Decryption for this routine is simple: anyone who knows the secret key can create the same cipher and decrypt the message using the internal state:

![[ecb.png]]
_Source: https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation_

Blocks are computed independently, so it is relatively easy to decrypt any block in the encrypted output, so long as the bytes fetched align with a block boundary. But ECB has a particular vulnerability: _any input blocks that are identical produce identical outputs_. This might not seem serious when encrypting text—the input text must repeat reliably such that it produces identical input blocks, which seems unrealistic in most scenarios. But what if the input is not characters but data? Data can often repeat, for example in images that have large portions of identical coloring. Enter the infamous ECB penguin:

![[ecb_penguin.png]]

Because so much of the penguin data is identical (blocks of black and white pixels), the encrypted image leaks information about the underlying data! For that reason we must turn to more secure means of encryption, such as AES-CBC mode.

#### CBC Mode

AES-CBC mode stands for Cipher Block Chaining. This refers to the fact that an input block is altered before encryption by "chaining" together output from the previous block. The result of the algorithm resolves to `c[i] = (m[i] ^ c[i-1]) ^ s` where `c[i]` is the output of the current block, `m[i]` is the input of the current block, `c[i-1]` is the ciphertext output of the prior block, and `s` is the internal state based on the secret key. For the first block there is no `c[i-1]` so a block-size pseudo-random _Initialization Vector_ (IV) is chosen to inject some randomness into the input. This is shown pictorially below:

![[cbc.png]]
_Source: https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation_

It is still possible for any user with the secret key _and_ IV to decrypt an arbitrary block `c[i]` presuming they also have the ciphertext from the previous block `c[i-1]`. This is done by computing `m[i] = (c[i] ^ s) ^ c[i-1]`. 

Because the input is preemptively XORd with the prior block's output, identical input blocks will generate unique ciphertext output. This solves the issue with the ECB penguin and the output of AES-CBC for the image is pseudo-random, like the rightmost panel above. 

While CBC mode fixes this error, it is still victim to certain attack vectors if its implementation and output are used incorrectly. 

#### Padding
- Situation: when the number of data (msg) != multiple of block size and we still wanna encrypt the data using AES
	- Why is this a problem? Because AES relies on blocks of data
	- Solution: pad the data
		- Things to consider
			- how to communicate that the padding is just padding, not part of the data?
				- If you need to add 11 (0xb) padding bytes, you make these padding bytes have the value 0xb
				- Take the padded data and feed it to encryption
				- When I want to decrypt it, I look at the last byte's value - that should tell me the number of padding bytes. I look at final bytes equal to this number and see if they all equal the last byte's value. If yes, they are all padding bytes and we throw them out

AES relies on blocks of data, and not every message has a block-aligned length. The algorithm solves this dilemma with _padding_. Padding is simply bytes appended to the end of an encrypted message so that its length is a multiple of the block length. Choice of padding could be arbitrary, but it is important to define a scheme such that padding is recognizable—the recipient should be able to distinguish the difference between the original message `m` and its padding, which can be effectively discarded.

There are many padding options available, and a popular choice is [PKCS-7](https://stackoverflow.com/questions/34865313/bouncy-castle-pkcs7-padding). This padding is rather trivial but elegant in its implementation. Consider the final block of a message, `m[n-1]` where `n` is the number of blocks in the message. This message is being encrypted with AES-128 which requires 128-bit (16-byte) blocks. If `len(m[n-1])` is not 16 bytes, we need to make it so. Say `len(m[n-1]) + p = 16`, where `p` is the length of the padding. We define the padding bytes to be equal to the length `p` that satisfies the above equation. That means if `p` is three, AES appends three `\x03` bytes to the message and encrypts the block. The exception to this rule is when `p` is zero, _we append a full block of `<block size>` bytes to the message_. For AES-128, this would be 16 `0x10`s.

> The appended padding bytes are raw bytes (e.g., `0x3`), not their ASCII representation (e.g., `'3'`).

This is a slick implementation because we can each find and strip the padding bytes in the last block. The last byte in the message block defines the number of padding bytes that can be stripped. If we see that `m[:-1]` is three, we strip three `0x3`s from the end. If it is `0x10`, we strip a full block of `0x10`s. Simple!

### Padding Oracle Attacks

Padding is an easy and effective way of solving the AES requirement that all input be in block-length segments. But it also exposes a potential attack vector: padding oracle attacks. This attack vector arises because clients and servers often perform padding validation as a step in ensuring the message was transmitted, received, and decrypted properly—if the padding does not match expectations then the message is incorrectly transmitted/received at best, and potentially nefarious at worst. It's safer just to throw away the packet and inform the other party that the message was not received.

In the event of bad padding, the target might send a response or behave differently. Similar to [[11. SQLi#Blind SQLi|blind SQL injection]], any indicator such as timing or a different response indicating this occurrence can open an attack vector: a _padding oracle attack_. 

Consider a target which is listening for an encrypted transmission and responds based on if it successfully decrypted and confirmed the message's padding. The response serves as an "oracle"—we can glean that padding was correctly or incorrectly applied based on some aspect of the response. If we intercept an authentic encrypted message that we want to crack, we can use this methodology to break encryption and read the message. Let's take a look at how this is done in practice.

Consider the _last block_ of an AES128-CBC encrypted transmission which contains 16 pseudo-random bytes. We'll call this block `c_n` and each byte in in the block is `c_n[i]`. To understand this attack, we need to define another buffer representing the "internal state" of the block cipher. We'll call this `s` and represent it also as a sequence of 16 bytes. We define this state as the sequence of bytes such that the last block of ciphertext is the XOR of the last block of message text, the internal cipher state, and the prior block of ciphertext: `c_n = (m_n ^ s) ^ c_(n-1)`. This is represented pictorially below:

![[padding_oracle.png]]

The key to a padding oracle attack is that we, as an attacker, send a _ciphertext_ to the server and the server tells us if it was padded correctly. Any intercepted ciphertext `c` from a third party is presumably valid, so sending `c` to the server should return a positive response. But, we can manipulate that ciphertext and send the manipulated result to the server.

Let's turn our attention again to the last block of the message, which is what the server will check for valid padding. Let's say we start manipulating the last byte of the ciphertext that we send for validation, byte `c_n[15]`. Manipulation presumably affects the decryption, likely triggering an invalid response. But, _there is guaranteed to be at least one byte that makes it respond positively_. Let's say when we change `c_n[15]` to value `X_15` which, when decrypted, outputs `0x1`. Since this is technically valid padding, the server would respond with a positive response! 

![[padding_oracle_0.png]]

Knowing this, we can determine other portions of the system, specifically `s[15]`. Using our previous algorithm, `m_n[15] = c_n[15] ^ s[15] ^ c_(n-1)[15]`. We chose `c[15] = X_15` and we know `c(n-1)[15]` from the original ciphertext. If the server confirms our padding then we know the manipulated `m[15]` is  `0x1` and we can solve for `s[15]`. What does this give us? First, it allows us to calculate the _original message text byte!_ We can do this by leveraging the found `s[15]` byte, meaning `m_n[15] = c_n[15] ^ s[15] ^ c_(n-1)[15]` (where `c_n[15]` is from the original ciphertext, not the manipulated `X_15` we used in the attack). But that's only a single byte in the message, which does not tell us a lot.

The second thing that `s[15]`'s value provides is continuation of this attack. Next, we'll turn our focus to `m_n[14]` in the same way we targeted `m_n[15]`. But to get insight on `s[14]` we again need to provide valid padding. In this case, we need to end the decrypted message with two `0x2` bytes. Let's break down how we can do that.

![[padding_oracle_1.png]]

Once again, we can try and manipulate byte `c_n[14]` by brute forcing the server until we get a valid response. But for the response to be valid, we also need to include byte `c_n[15]` that decrypts to `0x2`. We can make sure this occurs by calculating the required input byte `X'_15`, such that `X'_15 ^ s[15] ^ c_(n-1)[15] = 0x2`! Since we know all other variables in that equation, we can solve for `X'_15` and include that as the last byte of the ciphertext. Eventually, we'll get a positive response indicating the padding was valid. Once again, we can calculate an internal state byte—this time `s[14]`—using the equation `m_n[14] = c_n[14] ^ s[14] ^ c_(n-1)[14]` where `c_n[14]` is the manipulated byte `X_14` and `m_n[14]` in this case is `0x2`. With that byte solve, we can decrypt another original message byte and continue our attack.

Continuing on, we will eventually decrypt all bytes in the block up until the last byte. This can proceed like before, but in this case all `X'` bytes are calculated such that they decrypt to `0x10`. We again manipulate byte `c_n[0]` like the others until a valid message returns. 

![[padding_oracle_2.png]]

Once again, we can then calculate `s[0]` such that we have broken the internal state for the last encrypted block! We can decrypt the entire block to find `m_n = c_n ^ s ^ c_(n-1)`! _This strategy works not just for the last block, but can be applied to any block in the ciphertext_. Since the feedback is only based on whether the padding is correct, we can choose a block of ciphertext, say block `c_m`, and arbitrarily make _that_ the last block. The server will assess it as if it was, and we can eventually calculate the internal state bytes for block `c_m`. In the same way, we can then decrypt `m_m = c_m ^ s ^ c_(m-1)`. This attack can therefore be applied to the entire message, block by block, to decrypt the original message!

> Note that when attacking block `c_0` there is no `c_(-1)`—rather, we use the initialization vector, IV. The IV is always transmitted at the beginning of an encryption routine, and is sometimes transmitted in plaintext because it is a random number.

## Recitation

#### Recitation 13.0

Given `e1 = 13` and `e2 = 15`, find `a` such that `a * e1 + b * e2 = 1`. Use the fact that we can remove one of the terms by taking the entire equation mod _some value_.

#### Recitation 13.1

Using the solution for `a` from above, find `b` such that `a * e1 + b * e2 = 1`. Confirm the equation holds.

#### Recitation 13.2

With `a` and `b` from above, find `m` if we have the following values:

```
n = 103109065902334620226101162008793963504256027939117020091876799039690801944735604259018655534860183205031069083254290258577291605287053538752280231959857465853228851714786887294961873006234153079187216285516823832102424110934062954272346111907571393964363630079343598511602013316604641904852018969178919051627
c1 = 98165528588897581357762737834689451362252757422664514540538121132831138195216264938258509140640778717781569080958991098729015566777580593509402612574625430419832053337731308491289074351255823858676879185727045495590514663530030231806055096448879914474800546120932100906434044055982738517132870631903309747388
c2 = 102475188247563848286945915380476667802602854876368431885335322709108972931825158123667293750369168229919151668978059761534237040449685498674713242003659107451198242719915205456598334223051250662805244834468165714315564160456345356775214718947496000390960566077219957635569079685758176360540536491609062295912
```

## Next Steps

Cryptography is an incredibly deep field, and this lesson only scratched the surface. There are plenty of other algorithms used in the wild that are subject to common pitfalls and misconfigurations. There are also proprietary cryptographic protocols which should be rigorously vetted, as "rolling your own crypto" is extremely hard and error prone.

A good way to continue building breadth and depth in the security of cryptography is CTF-adjacent sites [Cryptohack](https://cryptohack.org/) and [Cryptopals](https://cryptopals.com/). These are sites with curated learning tracks that build fundamental understanding of the challenges before diving into hacking vulnerable implementations. They are also built for newcomers to cryptography, which is extremely beneficial for those of us who are curious but have a limited background in mathematics. These are also useful references when encountering an unfamiliar cryptographic implementation in the wild, as they can quickly build understanding when reverse engineering exchanges between clients and target systems.